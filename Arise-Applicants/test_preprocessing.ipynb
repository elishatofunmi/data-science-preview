{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "read_data = pd.read_csv('2019_4_2_02379003-6369-43bf-b444-842420685d06.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['clientId', 'clientIncome', 'incomeVerified', 'clientAge',\n",
       "       'clientGender', 'clientMaritalStatus', 'clientLoanPurpose',\n",
       "       'clientResidentialStauts', 'clientState', 'clientTimeAtEmployer',\n",
       "       'clientNumberPhoneContacts', 'clientAvgCallsPerDay', 'loanType',\n",
       "       'loanNumber', 'applicationDate', 'approvalDate', 'declinedDate',\n",
       "       'disbursementDate', 'payout_status', 'dueDate', 'paidAt', 'loanAmount',\n",
       "       'interestRate', 'loanTerm', 'max_amount_taken', 'max_tenor_taken',\n",
       "       'paymentRatio', 'FirstPaymentDefault', 'loanDefault'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "read_data['incomeVerified'][read_data['incomeVerified'] == 'true'] = 1\n",
    "read_data['incomeVerified'][read_data['incomeVerified'] == 'false'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "read_data = read_data.drop('loanType', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "read_data['clientResidentialStauts'][read_data['clientResidentialStauts']== 'Null'] = 'Rented'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LAGOS          60667\n",
       "OGUN           14798\n",
       "ABUJA          13999\n",
       "OYO            12731\n",
       "RIVERS          7829\n",
       "DELTA           5081\n",
       "KWARA           3969\n",
       "OSUN            3816\n",
       "ONDO            3571\n",
       "KADUNA          3496\n",
       "EDO             2663\n",
       "NIGER           2462\n",
       "BENUE           2043\n",
       "EKITI           2023\n",
       "AKWA IBOM       1960\n",
       "KOGI            1896\n",
       "PLATEAU         1715\n",
       "CROSS RIVER     1608\n",
       "NASARAWA        1589\n",
       "ENUGU           1566\n",
       "ANAMBRA         1496\n",
       "ABIA            1426\n",
       "IMO             1287\n",
       "KANO            1233\n",
       "BAYELSA         1179\n",
       "ADAMAWA          569\n",
       "BAUCHI           418\n",
       "SOKOTO           398\n",
       "EBONYI           392\n",
       "TARABA           336\n",
       "KEBBI            279\n",
       "GOMBE            265\n",
       "KATSINA          248\n",
       "ZAMFARA          221\n",
       "BORNO            210\n",
       "YOBE              83\n",
       "JIGAWA            72\n",
       "LAGOS              1\n",
       "OJO                1\n",
       "Name: clientState, dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_data['clientState'][read_data['clientState'] == 'Null'] = 'LAGOS'\n",
    "read_data['clientState'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Married      85492\n",
       "Single       71361\n",
       "Separated     1795\n",
       "Widowed        939\n",
       "Null             6\n",
       "Divorced         3\n",
       "Name: clientMaritalStatus, dtype: int64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_data['clientMaritalStatus'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "read_data['clientMaritalStatus'][read_data['clientMaritalStatus']== 'Null'] = 'Married'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business     78976\n",
       "other        31554\n",
       "house        22240\n",
       "education    15737\n",
       "medical      11089\n",
       "Name: clientLoanPurpose, dtype: int64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_data['clientLoanPurpose'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rented               101670\n",
       "Own Residence         26406\n",
       "Family Owned          25668\n",
       "Employer Provided      5589\n",
       "Temp. Residence         263\n",
       "Name: clientResidentialStauts, dtype: int64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_data['clientResidentialStauts'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.get_dummies(read_data,prefix_sep = '_', columns = ['clientGender', 'clientState', 'clientMaritalStatus',\n",
    "                                         'clientLoanPurpose', 'clientResidentialStauts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clientId</th>\n",
       "      <th>clientIncome</th>\n",
       "      <th>incomeVerified</th>\n",
       "      <th>clientAge</th>\n",
       "      <th>clientTimeAtEmployer</th>\n",
       "      <th>clientNumberPhoneContacts</th>\n",
       "      <th>clientAvgCallsPerDay</th>\n",
       "      <th>loanNumber</th>\n",
       "      <th>applicationDate</th>\n",
       "      <th>approvalDate</th>\n",
       "      <th>...</th>\n",
       "      <th>clientLoanPurpose_business</th>\n",
       "      <th>clientLoanPurpose_education</th>\n",
       "      <th>clientLoanPurpose_house</th>\n",
       "      <th>clientLoanPurpose_medical</th>\n",
       "      <th>clientLoanPurpose_other</th>\n",
       "      <th>clientResidentialStauts_Employer Provided</th>\n",
       "      <th>clientResidentialStauts_Family Owned</th>\n",
       "      <th>clientResidentialStauts_Own Residence</th>\n",
       "      <th>clientResidentialStauts_Rented</th>\n",
       "      <th>clientResidentialStauts_Temp. Residence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>719046128</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>36+</td>\n",
       "      <td>2976</td>\n",
       "      <td>51.40909090909091</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-03-18</td>\n",
       "      <td>2018-03-18</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>821565030</td>\n",
       "      <td>105000.00</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>36+</td>\n",
       "      <td>1159</td>\n",
       "      <td>121.03645833333333</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-01-06</td>\n",
       "      <td>2018-01-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>703822576</td>\n",
       "      <td>78029.19</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>36+</td>\n",
       "      <td>1375</td>\n",
       "      <td>13.402912621359222</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-04-27</td>\n",
       "      <td>2018-04-27</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    clientId  clientIncome incomeVerified  clientAge clientTimeAtEmployer  \\\n",
       "0  719046128      25000.00              1         38                  36+   \n",
       "1  821565030     105000.00              0         31                  36+   \n",
       "2  703822576      78029.19              1         38                  36+   \n",
       "\n",
       "  clientNumberPhoneContacts clientAvgCallsPerDay  loanNumber applicationDate  \\\n",
       "0                      2976    51.40909090909091           4      2018-03-18   \n",
       "1                      1159   121.03645833333333           4      2018-01-06   \n",
       "2                      1375   13.402912621359222           4      2018-04-27   \n",
       "\n",
       "  approvalDate                   ...                     \\\n",
       "0   2018-03-18                   ...                      \n",
       "1   2018-01-06                   ...                      \n",
       "2   2018-04-27                   ...                      \n",
       "\n",
       "  clientLoanPurpose_business clientLoanPurpose_education  \\\n",
       "0                          1                           0   \n",
       "1                          0                           0   \n",
       "2                          0                           1   \n",
       "\n",
       "  clientLoanPurpose_house clientLoanPurpose_medical clientLoanPurpose_other  \\\n",
       "0                       0                         0                       0   \n",
       "1                       1                         0                       0   \n",
       "2                       0                         0                       0   \n",
       "\n",
       "   clientResidentialStauts_Employer Provided  \\\n",
       "0                                          0   \n",
       "1                                          0   \n",
       "2                                          0   \n",
       "\n",
       "   clientResidentialStauts_Family Owned  \\\n",
       "0                                     0   \n",
       "1                                     0   \n",
       "2                                     1   \n",
       "\n",
       "   clientResidentialStauts_Own Residence  clientResidentialStauts_Rented  \\\n",
       "0                                      0                               1   \n",
       "1                                      0                               1   \n",
       "2                                      0                               0   \n",
       "\n",
       "   clientResidentialStauts_Temp. Residence  \n",
       "0                                        0  \n",
       "1                                        0  \n",
       "2                                        0  \n",
       "\n",
       "[3 rows x 79 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.drop(['applicationDate', 'approvalDate', 'declinedDate',\n",
    "       'disbursementDate', 'payout_status', 'dueDate', 'paidAt'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = data.drop(['clientId', 'clientNumberPhoneContacts'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incomeVerified 103\n",
      "clientTimeAtEmployer 159596\n",
      "clientAvgCallsPerDay 159596\n"
     ]
    }
   ],
   "source": [
    "for k in x.columns:\n",
    "    value = sum([isinstance(i, str) for i in x[k]])\n",
    "    if value > 1:\n",
    "        print(k, value)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       133286\n",
       "1        26207\n",
       "Null       103\n",
       "Name: incomeVerified, dtype: int64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['incomeVerified'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x['incomeVerified'][x['incomeVerified']== 'Null'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x['clientTimeAtEmployer'][x['clientTimeAtEmployer']== 'Null'] = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = x.drop(['clientTimeAtEmployer', 'clientAvgCallsPerDay'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'loanDefault' in x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159596,)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = x['loanDefault']\n",
    "x = x.drop('loanDefault', axis = 1)\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "test = SelectKBest(score_func =chi2, k = 4)\n",
    "fit = test.fit(x,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.060e+07   3.275e+02   5.687e+02   1.774e+03   1.050e+06   1.497e+03\n",
      "   2.434e+02   4.778e+02   1.465e+02   4.024e+04   4.386e+04   7.575e+01\n",
      "   3.449e+01   1.218e-02   8.140e+01   1.773e+00   1.658e+00   5.117e+00\n",
      "   2.669e+00   9.298e+00   9.388e+00   2.259e+00   2.538e-01   2.758e+00\n",
      "   4.705e+00   4.986e-01   5.502e+01   1.777e+00   5.008e-01   3.192e+00\n",
      "   1.829e+00   9.236e-01   1.051e+01   1.838e+00   8.678e+00   6.232e+01\n",
      "   6.619e+01   1.533e+02   3.887e-01   8.600e-02   1.393e+02   1.625e+01\n",
      "   2.573e+00   2.665e+01   6.814e+01   1.203e+02   3.348e+00   1.188e+00\n",
      "   3.912e-01   1.611e-02   2.976e-01   7.739e-02   4.251e-02   3.736e+01\n",
      "   3.664e+00   5.172e+01   2.998e+00   4.299e+02   4.079e+01   2.212e+02\n",
      "   1.163e+01   3.178e+02   6.109e+01   1.793e+00   1.464e+01   2.981e-01\n",
      "   3.633e-02]\n"
     ]
    }
   ],
   "source": [
    "# summarize scores\n",
    "np.set_printoptions(precision = 3)\n",
    "print(fit.scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.500e+04   4.800e+04   0.000e+00   1.000e+00]\n",
      " [  1.050e+05   3.150e+04   0.000e+00   0.000e+00]\n",
      " [  7.803e+04   1.295e+05   0.000e+00   0.000e+00]\n",
      " [  3.500e+04   1.750e+04   0.000e+00   0.000e+00]\n",
      " [  3.500e+05   1.325e+05   0.000e+00   1.000e+00]]\n"
     ]
    }
   ],
   "source": [
    "features = fit.transform(x)\n",
    "# summarize selected features\n",
    "print(features[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((159596, 67), (159596, 4))"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 2)\n",
    "pmodel = pca.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999991353114115"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "principalDf = pd.DataFrame(data = pmodel, columns = ['principal component 1', 'principal component 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>principal component 1</th>\n",
       "      <th>principal component 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-64458.453741</td>\n",
       "      <td>18454.488372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13766.816133</td>\n",
       "      <td>-5062.749725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4422.734353</td>\n",
       "      <td>94940.114792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-57197.704160</td>\n",
       "      <td>-12811.086747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>266745.894982</td>\n",
       "      <td>73852.253484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   principal component 1  principal component 2\n",
       "0          -64458.453741           18454.488372\n",
       "1           13766.816133           -5062.749725\n",
       "2           -4422.734353           94940.114792\n",
       "3          -57197.704160          -12811.086747\n",
       "4          266745.894982           73852.253484"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display principal components\n",
    "principalDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159596,)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "principalDf['target'] = target"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2 Component PCA', fontsize = 20)\n",
    "\n",
    "\n",
    "targets = [0, 1]\n",
    "colors = ['r', 'g']\n",
    "for target, color in zip(targets,colors):\n",
    "    ax.scatter(principalDf['principal component 1']\n",
    "               , principalDf['principal component 2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "ax.legend(targets)\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_max = MinMaxScaler()\n",
    "std = StandardScaler()\n",
    "norm = Normalizer()\n",
    "\n",
    "x_new = min_max.fit_transform(features)\n",
    "x_std = std.fit_transform(x_new)\n",
    "x_norm = std.fit_transform(x_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159596,)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_norm, target, test_size = 0.4, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84373988324613347"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.fit(x_train, y_train)\n",
    "log.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = log.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63839,)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=0, splitter='best')"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state = 0)\n",
    "tree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.87921509654646657, 0.84605022008490105)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_score = tree.score(x_train, y_train)\n",
    "prediction = log.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "test_score = accuracy_score(prediction, y_test)\n",
    "train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.846862370375 0.846050220085\n",
      "0.846862370375 0.846050220085\n",
      "0.847227878902 0.846050220085\n",
      "0.848199087273 0.846050220085\n",
      "0.848449721691 0.846050220085\n",
      "0.849044978435 0.846050220085\n",
      "0.849556690373 0.846050220085\n"
     ]
    }
   ],
   "source": [
    "for i in range(3,10):\n",
    "    tree = DecisionTreeClassifier(random_state = 0, max_depth = i)\n",
    "    tree.fit(x_train, y_train)\n",
    "    train_score = tree.score(x_train, y_train)\n",
    "    prediction = log.predict(x_test)\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    test_score = accuracy_score(prediction, y_test)\n",
    "    print(train_score, test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.011,  0.015,  0.175,  0.799])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=5, n_jobs=1, oob_score=False, random_state=2,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators = 5, random_state = 2)\n",
    "forest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87403531856678884"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8398627798054481"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = forest.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "test_score = accuracy_score(prediction, y_test)\n",
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.879162881043 0.846050220085\n",
      "0.879204653446 0.846050220085\n",
      "0.879215096546 0.846050220085\n",
      "0.879215096546 0.846050220085\n"
     ]
    }
   ],
   "source": [
    "for i in [100,150,200,250]:\n",
    "    tree = RandomForestClassifier(random_state = 0, n_estimators = i)\n",
    "    tree.fit(x_train, y_train)\n",
    "    train_score = tree.score(x_train, y_train)\n",
    "    prediction = log.predict(x_test)\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    test_score = accuracy_score(prediction, y_test)\n",
    "    print(train_score, test_score)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "skfolds = StratifiedKFold(n_splits = 3, random_state = 42)\n",
    "\n",
    "for train_index, test_index in skfolds.split(x_train, y_train):\n",
    "    clone_clf = clone(forest)\n",
    "    x_train_folds = x_train[train_index]\n",
    "    y_train_folds = y_train[train_index]\n",
    "    x_test_fold = x_train[test_index]\n",
    "    y_test_fold = y_train[test_index]\n",
    "    \n",
    "    clone_clf.fit(x_train_folds, y_train_folds)\n",
    "    y_pred = clone_clf.predict(x_test_fold)\n",
    "    n_correct = sum(y_pred == y_test_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.837,  0.837,  0.841,  0.836])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(forest, x_train, y_train, cv = 4, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((63839,), (63839,))"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape, prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEKCAYAAADpfBXhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21ec634f7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, prediction)\n",
    "\n",
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], 'b--', label = 'precision')\n",
    "    plt.plot(thresholds, recalls[:-1], 'g--', label = 'recall')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.legend(loc = 'center left')\n",
    "    plt.ylim([0,1])\n",
    "    plt.show()\n",
    "    \n",
    "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEKCAYAAAAMzhLIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nicIYY0y1/h8fMbf5X3ND4QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21ec6910c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, prediction)\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, label = None):\n",
    "    plt.plot(fpr, tpr, linewidth= 2, label = label)\n",
    "    plt.plot([0,1], [0,1], 'k--')\n",
    "    plt.axis([0,1,0,1])\n",
    "    plt.xlabel('false positive rate')\n",
    "    plt.ylabel('true positive rate')\n",
    "plot_roc_curve(fpr, tpr, thresholds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79428446970103606"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sk.metrics.con"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "forest = RandomForestClassifier(random_state = 42)\n",
    "from sklearn.cross_validation import cross_val_predict, cross_val_score\n",
    "y_proba_forest = cross_val_predict(forest, x_train, y_train, cv = 3)\n",
    "y_scores_forest = y_proba_forest[:,1]\n",
    "fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train, y_scores_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[63425,  5543],\n",
       "       [ 9908, 16881]])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cross_val_score(forest, x_train, y_train, cv = 3, scoring = 'accuracy')\n",
    "y_train_pred = cross_val_predict(forest, x_train, y_train, cv =3)\n",
    "conf_mx = confusion_matrix(y_train, y_train_pred)\n",
    "conf_mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAECCAYAAADesWqHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABZVJREFUeJzt2zGPVHUUxuFzYGNNwVZgWApiQr3xM2BlK7UJlR+AL2JD\nQew0lhYmtjYWLJ1GTIiJERvX0NEYkmMhBVYzu86du8v7PN1MJn/e5O5v7wy72zNTQJYraw8A9k/4\nEEj4EEj4EEj4EEj4EEj4Z9Dd97r7l+5+3t0P197D9rr7cXf/2d0/rr3lIhD+lrr7alV9XlUfVdXd\nqrrf3XfXXcUZfFFV99YecVEIf3sfVtXzmfl1Zv6uqq+q6uOVN7Glmfm+ql6uveOiEP72blTV7289\nfvHmObh0hA+BhL+9P6rq/bce33zzHFw6wt/ek6q60923u/u9qvqkqr5ZeROci/C3NDOvq+qzqvqu\nqn6uqq9n5qd1V7Gt7v6yqn6oqg+6+0V3f7r2pjW1P8uFPO74EEj4EEj4EEj4EEj4EEj4Z9TdD9be\nwPm5fv8S/tn5wrncXL8SPkRa5Bd4rl+/PkdHRzs/9yI4PT2tw8PDtWcs6unTp2tP4H+Ymd70moMl\n/uGjo6M6OTlZ4mj2oHvj1w2XnLf6EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4\nEEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4\nEEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EGir\n8Lv7Xnf/0t3Pu/vh0qOAZW0Mv7uvVtXnVfVRVd2tqvvdfXfpYcBytrnjf1hVz2fm15n5u6q+qqqP\nl50FLGmb8G9U1e9vPX7x5jngktrZf+5194PuPunuk9PT010dCyxgm/D/qKr333p8881z/zEzj2bm\neGaODw8Pd7UPWMA24T+pqjvdfbu736uqT6rqm2VnAUs62PSCmXnd3Z9V1XdVdbWqHs/MT4svAxaz\nMfyqqpn5tqq+XXgLsCd+cw8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8C\nCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8C\nCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8C9czs/NCD\ng4O5du3azs9lP27durX2BM7p2bNn9erVq970Ond8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8\nCCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8\nCCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8\nCCR8CCR8CCR8CCR8CLQx/O5+3N1/dveP+xgELG+bO/4XVXVv4R3AHm0Mf2a+r6qXe9gC7InP+BDo\nYFcHdfeDqnpQVXXliu8ncJHtrNCZeTQzxzNz3N27OhZYgFszBNrmx3lfVtUPVfVBd7/o7k+XnwUs\naeNn/Jm5v48hwP54qw+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+B\nhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+B\nhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BemZ2f2j3aVX9\ntvODL4brVfXX2iM4t3f9+t2amcNNL1ok/HdZd5/MzPHaOzgf1+9f3upDIOFDIOGf3aO1B/C/uH7l\nMz5EcseHQMKHQMKHQMKHQMKHQP8Ay6GwDQeSjUEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21ec696a780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(conf_mx, cmap = plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoosting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.849065864637 0.85021695202\n",
      "0.850308593628 0.850545904541\n",
      "0.851248472697 0.849887999499\n",
      "0.852574746494 0.850295274049\n",
      "0.855853880134 0.849527718166\n",
      "0.857744081373 0.848948135152\n",
      "0.860271311758 0.848572189414\n",
      "0.86316405067 0.848023935212\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "for i in range(2,10):\n",
    "    gbrt = GradientBoostingClassifier(random_state = 0, max_depth = i)\n",
    "    gbrt.fit(x_train, y_train)\n",
    "    print(gbrt.score(x_train, y_train),gbrt.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(solver = 'lbfgs', activation = 'relu', random_state = 0).fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84854370959825387"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.84725920820409995, 0.8493710741083037)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(solver = 'lbfgs', activation = 'logistic', random_state = 0, hidden_layer_sizes = [10]).fit(x_train, y_train)\n",
    "mlp.score(x_train, y_train), mlp.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.84738452541328568, 0.84940240291984526)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(solver = 'lbfgs', max_iter = 1000, alpha = 1, activation = 'logistic', random_state = 0, hidden_layer_sizes = [10]).fit(x_train, y_train)\n",
    "mlp.score(x_train, y_train), mlp.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.84050252200883491, 0.84214978304798005)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precetrons\n",
    "from sklearn.linear_model import Perceptron\n",
    "per_clf = Perceptron(random_state = 42)\n",
    "per_clf.fit(x_train, y_train)\n",
    "y_pred = per_clf.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "test_score = accuracy_score(y_pred, y_test)\n",
    "per_clf.score(x_train, y_train),test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\INVENTAR\\AppData\\Local\\Temp\\tmp5tlx89ug\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000021EC8840B38>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'C:\\\\Users\\\\INVENTAR\\\\AppData\\\\Local\\\\Temp\\\\tmp5tlx89ug'}\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "WARNING:tensorflow:From C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\INVENTAR\\AppData\\Local\\Temp\\tmp5tlx89ug\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.680682, step = 1\n",
      "INFO:tensorflow:global_step/sec: 206.137\n",
      "INFO:tensorflow:loss = 0.407919, step = 101 (0.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.327\n",
      "INFO:tensorflow:loss = 0.334438, step = 201 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.416\n",
      "INFO:tensorflow:loss = 0.271743, step = 301 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.011\n",
      "INFO:tensorflow:loss = 0.361544, step = 401 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.381\n",
      "INFO:tensorflow:loss = 0.401049, step = 501 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.408\n",
      "INFO:tensorflow:loss = 0.326332, step = 601 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.136\n",
      "INFO:tensorflow:loss = 0.341803, step = 701 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.138\n",
      "INFO:tensorflow:loss = 0.355674, step = 801 (0.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.637\n",
      "INFO:tensorflow:loss = 0.351962, step = 901 (0.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.188\n",
      "INFO:tensorflow:loss = 0.363271, step = 1001 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.582\n",
      "INFO:tensorflow:loss = 0.367145, step = 1101 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.174\n",
      "INFO:tensorflow:loss = 0.364283, step = 1201 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.487\n",
      "INFO:tensorflow:loss = 0.445843, step = 1301 (0.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.455\n",
      "INFO:tensorflow:loss = 0.316225, step = 1401 (0.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.826\n",
      "INFO:tensorflow:loss = 0.38922, step = 1501 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.771\n",
      "INFO:tensorflow:loss = 0.344475, step = 1601 (0.527 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.541\n",
      "INFO:tensorflow:loss = 0.295004, step = 1701 (0.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.614\n",
      "INFO:tensorflow:loss = 0.401626, step = 1801 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.495\n",
      "INFO:tensorflow:loss = 0.281009, step = 1901 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.187\n",
      "INFO:tensorflow:loss = 0.263319, step = 2001 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.310772, step = 2101 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.495\n",
      "INFO:tensorflow:loss = 0.353159, step = 2201 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.141\n",
      "INFO:tensorflow:loss = 0.289763, step = 2301 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.741\n",
      "INFO:tensorflow:loss = 0.367555, step = 2401 (0.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.356\n",
      "INFO:tensorflow:loss = 0.447073, step = 2501 (0.515 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.164\n",
      "INFO:tensorflow:loss = 0.409175, step = 2601 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.783\n",
      "INFO:tensorflow:loss = 0.370954, step = 2701 (0.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.303\n",
      "INFO:tensorflow:loss = 0.338782, step = 2801 (0.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.049\n",
      "INFO:tensorflow:loss = 0.473819, step = 2901 (0.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.624\n",
      "INFO:tensorflow:loss = 0.316661, step = 3001 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.522\n",
      "INFO:tensorflow:loss = 0.344282, step = 3101 (0.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.281\n",
      "INFO:tensorflow:loss = 0.35505, step = 3201 (0.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.772\n",
      "INFO:tensorflow:loss = 0.293067, step = 3301 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.371\n",
      "INFO:tensorflow:loss = 0.447342, step = 3401 (0.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.365\n",
      "INFO:tensorflow:loss = 0.343572, step = 3501 (0.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.669\n",
      "INFO:tensorflow:loss = 0.295509, step = 3601 (0.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 190.948\n",
      "INFO:tensorflow:loss = 0.327507, step = 3701 (0.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.853\n",
      "INFO:tensorflow:loss = 0.293329, step = 3801 (0.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.454\n",
      "INFO:tensorflow:loss = 0.405681, step = 3901 (0.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.448\n",
      "INFO:tensorflow:loss = 0.397802, step = 4001 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.607\n",
      "INFO:tensorflow:loss = 0.302636, step = 4101 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.975\n",
      "INFO:tensorflow:loss = 0.253013, step = 4201 (0.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.967\n",
      "INFO:tensorflow:loss = 0.375581, step = 4301 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.218\n",
      "INFO:tensorflow:loss = 0.304067, step = 4401 (0.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.25\n",
      "INFO:tensorflow:loss = 0.267473, step = 4501 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.677\n",
      "INFO:tensorflow:loss = 0.404513, step = 4601 (0.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.588\n",
      "INFO:tensorflow:loss = 0.374918, step = 4701 (0.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.538\n",
      "INFO:tensorflow:loss = 0.325809, step = 4801 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.567\n",
      "INFO:tensorflow:loss = 0.281437, step = 4901 (0.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.701\n",
      "INFO:tensorflow:loss = 0.306849, step = 5001 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.751\n",
      "INFO:tensorflow:loss = 0.345483, step = 5101 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.616\n",
      "INFO:tensorflow:loss = 0.35221, step = 5201 (0.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.801\n",
      "INFO:tensorflow:loss = 0.364564, step = 5301 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.156\n",
      "INFO:tensorflow:loss = 0.507392, step = 5401 (0.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.801\n",
      "INFO:tensorflow:loss = 0.349892, step = 5501 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.356\n",
      "INFO:tensorflow:loss = 0.379291, step = 5601 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.524\n",
      "INFO:tensorflow:loss = 0.346776, step = 5701 (0.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.409\n",
      "INFO:tensorflow:loss = 0.462961, step = 5801 (0.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.7\n",
      "INFO:tensorflow:loss = 0.291862, step = 5901 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.258\n",
      "INFO:tensorflow:loss = 0.399172, step = 6001 (0.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.613\n",
      "INFO:tensorflow:loss = 0.341946, step = 6101 (0.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.182\n",
      "INFO:tensorflow:loss = 0.328986, step = 6201 (0.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.627\n",
      "INFO:tensorflow:loss = 0.371105, step = 6301 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.153\n",
      "INFO:tensorflow:loss = 0.357912, step = 6401 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.803\n",
      "INFO:tensorflow:loss = 0.304766, step = 6501 (0.504 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 204.52\n",
      "INFO:tensorflow:loss = 0.2782, step = 6601 (0.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.093\n",
      "INFO:tensorflow:loss = 0.338286, step = 6701 (0.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.983\n",
      "INFO:tensorflow:loss = 0.276604, step = 6801 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.305\n",
      "INFO:tensorflow:loss = 0.288703, step = 6901 (0.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.809\n",
      "INFO:tensorflow:loss = 0.481335, step = 7001 (0.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.227\n",
      "INFO:tensorflow:loss = 0.460785, step = 7101 (0.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.276\n",
      "INFO:tensorflow:loss = 0.324349, step = 7201 (0.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.698\n",
      "INFO:tensorflow:loss = 0.221085, step = 7301 (0.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.105\n",
      "INFO:tensorflow:loss = 0.369403, step = 7401 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.776\n",
      "INFO:tensorflow:loss = 0.262691, step = 7501 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.888\n",
      "INFO:tensorflow:loss = 0.354269, step = 7601 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.036\n",
      "INFO:tensorflow:loss = 0.332688, step = 7701 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.001\n",
      "INFO:tensorflow:loss = 0.316996, step = 7801 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.728\n",
      "INFO:tensorflow:loss = 0.409981, step = 7901 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.159\n",
      "INFO:tensorflow:loss = 0.395285, step = 8001 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.108\n",
      "INFO:tensorflow:loss = 0.409065, step = 8101 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.758\n",
      "INFO:tensorflow:loss = 0.309986, step = 8201 (0.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.456\n",
      "INFO:tensorflow:loss = 0.36392, step = 8301 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.261\n",
      "INFO:tensorflow:loss = 0.347837, step = 8401 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.189\n",
      "INFO:tensorflow:loss = 0.414186, step = 8501 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.665\n",
      "INFO:tensorflow:loss = 0.339273, step = 8601 (0.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.197\n",
      "INFO:tensorflow:loss = 0.271268, step = 8701 (0.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.258\n",
      "INFO:tensorflow:loss = 0.312436, step = 8801 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.612\n",
      "INFO:tensorflow:loss = 0.25211, step = 8901 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.809\n",
      "INFO:tensorflow:loss = 0.340979, step = 9001 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.148\n",
      "INFO:tensorflow:loss = 0.348646, step = 9101 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.054\n",
      "INFO:tensorflow:loss = 0.378816, step = 9201 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.723\n",
      "INFO:tensorflow:loss = 0.384061, step = 9301 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.058\n",
      "INFO:tensorflow:loss = 0.420725, step = 9401 (0.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.629\n",
      "INFO:tensorflow:loss = 0.317457, step = 9501 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.125\n",
      "INFO:tensorflow:loss = 0.417595, step = 9601 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.076\n",
      "INFO:tensorflow:loss = 0.354066, step = 9701 (0.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.051\n",
      "INFO:tensorflow:loss = 0.287353, step = 9801 (0.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.557\n",
      "INFO:tensorflow:loss = 0.366556, step = 9901 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.466\n",
      "INFO:tensorflow:loss = 0.305494, step = 10001 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.343\n",
      "INFO:tensorflow:loss = 0.348318, step = 10101 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.919\n",
      "INFO:tensorflow:loss = 0.372622, step = 10201 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.765\n",
      "INFO:tensorflow:loss = 0.266307, step = 10301 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.603\n",
      "INFO:tensorflow:loss = 0.348109, step = 10401 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.057\n",
      "INFO:tensorflow:loss = 0.530116, step = 10501 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.125\n",
      "INFO:tensorflow:loss = 0.407626, step = 10601 (0.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.061\n",
      "INFO:tensorflow:loss = 0.319306, step = 10701 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.037\n",
      "INFO:tensorflow:loss = 0.291126, step = 10801 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.125\n",
      "INFO:tensorflow:loss = 0.33501, step = 10901 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.528\n",
      "INFO:tensorflow:loss = 0.306994, step = 11001 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.413\n",
      "INFO:tensorflow:loss = 0.353218, step = 11101 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.004\n",
      "INFO:tensorflow:loss = 0.352588, step = 11201 (0.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.124\n",
      "INFO:tensorflow:loss = 0.422094, step = 11301 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.542\n",
      "INFO:tensorflow:loss = 0.217375, step = 11401 (0.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.88\n",
      "INFO:tensorflow:loss = 0.38889, step = 11501 (0.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.216\n",
      "INFO:tensorflow:loss = 0.366403, step = 11601 (0.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.584\n",
      "INFO:tensorflow:loss = 0.351003, step = 11701 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.746\n",
      "INFO:tensorflow:loss = 0.452124, step = 11801 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.435\n",
      "INFO:tensorflow:loss = 0.437939, step = 11901 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.392\n",
      "INFO:tensorflow:loss = 0.297685, step = 12001 (0.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.751\n",
      "INFO:tensorflow:loss = 0.408383, step = 12101 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.906\n",
      "INFO:tensorflow:loss = 0.304284, step = 12201 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.587\n",
      "INFO:tensorflow:loss = 0.253718, step = 12301 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.241\n",
      "INFO:tensorflow:loss = 0.254567, step = 12401 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.433\n",
      "INFO:tensorflow:loss = 0.39535, step = 12501 (0.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.824\n",
      "INFO:tensorflow:loss = 0.363775, step = 12601 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.206\n",
      "INFO:tensorflow:loss = 0.3374, step = 12701 (0.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.392\n",
      "INFO:tensorflow:loss = 0.380659, step = 12801 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.849\n",
      "INFO:tensorflow:loss = 0.32889, step = 12901 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.697\n",
      "INFO:tensorflow:loss = 0.359333, step = 13001 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.878\n",
      "INFO:tensorflow:loss = 0.352186, step = 13101 (0.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.368\n",
      "INFO:tensorflow:loss = 0.279858, step = 13201 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.988\n",
      "INFO:tensorflow:loss = 0.380663, step = 13301 (0.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.88\n",
      "INFO:tensorflow:loss = 0.382859, step = 13401 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.877\n",
      "INFO:tensorflow:loss = 0.472759, step = 13501 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.02\n",
      "INFO:tensorflow:loss = 0.36269, step = 13601 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.385\n",
      "INFO:tensorflow:loss = 0.268966, step = 13701 (0.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.241\n",
      "INFO:tensorflow:loss = 0.415408, step = 13801 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.262\n",
      "INFO:tensorflow:loss = 0.428197, step = 13901 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.656\n",
      "INFO:tensorflow:loss = 0.3867, step = 14001 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.986\n",
      "INFO:tensorflow:loss = 0.277092, step = 14101 (0.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.287\n",
      "INFO:tensorflow:loss = 0.366966, step = 14201 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.784\n",
      "INFO:tensorflow:loss = 0.357502, step = 14301 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.672\n",
      "INFO:tensorflow:loss = 0.260411, step = 14401 (0.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.756\n",
      "INFO:tensorflow:loss = 0.299273, step = 14501 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.597\n",
      "INFO:tensorflow:loss = 0.313859, step = 14601 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.098\n",
      "INFO:tensorflow:loss = 0.26709, step = 14701 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.437\n",
      "INFO:tensorflow:loss = 0.313459, step = 14801 (0.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.374142, step = 14901 (0.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.041\n",
      "INFO:tensorflow:loss = 0.461166, step = 15001 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.572\n",
      "INFO:tensorflow:loss = 0.50199, step = 15101 (0.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.476\n",
      "INFO:tensorflow:loss = 0.304045, step = 15201 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.401\n",
      "INFO:tensorflow:loss = 0.318741, step = 15301 (0.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.863\n",
      "INFO:tensorflow:loss = 0.329337, step = 15401 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.014\n",
      "INFO:tensorflow:loss = 0.339571, step = 15501 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.063\n",
      "INFO:tensorflow:loss = 0.363548, step = 15601 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.206\n",
      "INFO:tensorflow:loss = 0.337681, step = 15701 (0.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.786\n",
      "INFO:tensorflow:loss = 0.330242, step = 15801 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.932\n",
      "INFO:tensorflow:loss = 0.370908, step = 15901 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.965\n",
      "INFO:tensorflow:loss = 0.362477, step = 16001 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.502\n",
      "INFO:tensorflow:loss = 0.32253, step = 16101 (0.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.712\n",
      "INFO:tensorflow:loss = 0.314644, step = 16201 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.05\n",
      "INFO:tensorflow:loss = 0.377392, step = 16301 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.699\n",
      "INFO:tensorflow:loss = 0.385944, step = 16401 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.737\n",
      "INFO:tensorflow:loss = 0.256793, step = 16501 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.605\n",
      "INFO:tensorflow:loss = 0.287504, step = 16601 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.938\n",
      "INFO:tensorflow:loss = 0.312659, step = 16701 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.42\n",
      "INFO:tensorflow:loss = 0.46239, step = 16801 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.737\n",
      "INFO:tensorflow:loss = 0.258965, step = 16901 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.955\n",
      "INFO:tensorflow:loss = 0.386437, step = 17001 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.744\n",
      "INFO:tensorflow:loss = 0.34637, step = 17101 (0.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.656\n",
      "INFO:tensorflow:loss = 0.34972, step = 17201 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.17\n",
      "INFO:tensorflow:loss = 0.238941, step = 17301 (0.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.838\n",
      "INFO:tensorflow:loss = 0.415274, step = 17401 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.025\n",
      "INFO:tensorflow:loss = 0.395431, step = 17501 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.987\n",
      "INFO:tensorflow:loss = 0.297236, step = 17601 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.677\n",
      "INFO:tensorflow:loss = 0.390261, step = 17701 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.292\n",
      "INFO:tensorflow:loss = 0.267313, step = 17801 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.077\n",
      "INFO:tensorflow:loss = 0.344792, step = 17901 (0.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.204\n",
      "INFO:tensorflow:loss = 0.239833, step = 18001 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.92\n",
      "INFO:tensorflow:loss = 0.421076, step = 18101 (0.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.431\n",
      "INFO:tensorflow:loss = 0.456185, step = 18201 (0.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.858\n",
      "INFO:tensorflow:loss = 0.300569, step = 18301 (0.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.176\n",
      "INFO:tensorflow:loss = 0.424405, step = 18401 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.273\n",
      "INFO:tensorflow:loss = 0.194092, step = 18501 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.297\n",
      "INFO:tensorflow:loss = 0.424446, step = 18601 (0.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.674\n",
      "INFO:tensorflow:loss = 0.303847, step = 18701 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.349\n",
      "INFO:tensorflow:loss = 0.291338, step = 18801 (0.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.031\n",
      "INFO:tensorflow:loss = 0.449388, step = 18901 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.476\n",
      "INFO:tensorflow:loss = 0.387421, step = 19001 (0.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.492\n",
      "INFO:tensorflow:loss = 0.43187, step = 19101 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.047\n",
      "INFO:tensorflow:loss = 0.271959, step = 19201 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.231\n",
      "INFO:tensorflow:loss = 0.326155, step = 19301 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.215\n",
      "INFO:tensorflow:loss = 0.382327, step = 19401 (0.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.964\n",
      "INFO:tensorflow:loss = 0.345732, step = 19501 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.036\n",
      "INFO:tensorflow:loss = 0.374675, step = 19601 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.262\n",
      "INFO:tensorflow:loss = 0.238862, step = 19701 (0.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.684\n",
      "INFO:tensorflow:loss = 0.321282, step = 19801 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.838\n",
      "INFO:tensorflow:loss = 0.333655, step = 19901 (0.465 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into C:\\Users\\INVENTAR\\AppData\\Local\\Temp\\tmp5tlx89ug\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.35866.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SKCompat()"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = tf.contrib.learn.infer_real_valued_columns_from_input(x_train)\n",
    "dnn_clf = tf.contrib.learn.DNNClassifier(hidden_units = [300,100], n_classes = 2,\n",
    "                                  feature_columns = feature_cols)\n",
    "dnn_clf = tf.contrib.learn.SKCompat(dnn_clf)\n",
    "dnn_clf.fit(x_train, y_train,batch_size = 100, steps = 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\INVENTAR\\AppData\\Local\\Temp\\tmp5tlx89ug\\model.ckpt-20000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85081219943921427"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = dnn_clf.predict(x_test)\n",
    "accuracy_score(y_test, y_pred['classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95757, 4)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training DNN using pure Tensorflow\n",
    "\n",
    "n_inputs =4\n",
    "n_hidden1 = 20\n",
    "n_hidden2 = 15\n",
    "n_outputs = 2\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = (200, n_inputs), name = 'X')\n",
    "y = tf.placeholder(tf.int64, shape = (200), name = 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_layer(x, n_neurons, name, activation = None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(x.get_shape()[1])\n",
    "        stddev = 2/np.sqrt(n_inputs + n_neurons)\n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev = stddev)\n",
    "        w =tf.Variable(init, name = 'kernel')\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name = 'bias')\n",
    "        z = tf.matmul(x, w) + b\n",
    "        if activation is not None:\n",
    "            return activation(z)\n",
    "        else:\n",
    "            return z\n",
    "        \n",
    "with tf.name_scope('dnn'):\n",
    "    hidden1 = neuron_layer(x, n_hidden1, name = 'hidden1', \n",
    "                          activation = tf.nn.relu)\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, name = 'hidden2', \n",
    "                           activation = tf.nn.relu)\n",
    "    logits = neuron_layer(hidden2, n_outputs, name = 'outputs')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with tf.name_scope('dnn_t'):\n",
    "    hidden1 = tf.layers.dense(x, n_hidden1, name = 'hidden1',\n",
    "                             activation = tf.nn.relu)\n",
    "    hidden2 = tf.layers.dense(hidden1, hidden2, name = hidden2, \n",
    "                             activation = tf.nn.relu)\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name = 'outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y,\n",
    "                                                             logits = logits)\n",
    "    loss = tf.reduce_mean(xentropy, name = 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('eval'):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "inint = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_val, test_x, y_val, test_y = train_test_split(x_test, y_test, test_size = 0.4, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Shape [-1,4] has negative dimensions\n\t [[Node: X_1 = Placeholder[dtype=DT_FLOAT, shape=[?,4], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'X_1', defined at:\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-263-91be3d937749>\", line 9, in <module>\n    x = tf.placeholder(tf.float32, shape = (None, n_inputs), name = 'X')\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1530, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 1954, in _placeholder\n    name=name)\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Shape [-1,4] has negative dimensions\n\t [[Node: X_1 = Placeholder[dtype=DT_FLOAT, shape=[?,4], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\INVENTAR\\Anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Shape [-1,4] has negative dimensions\n\t [[Node: X_1 = Placeholder[dtype=DT_FLOAT, shape=[?,4], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-314-e68410ecde8b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mstop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my_batch\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m             \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0macc_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mC:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1152\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Shape [-1,4] has negative dimensions\n\t [[Node: X_1 = Placeholder[dtype=DT_FLOAT, shape=[?,4], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'X_1', defined at:\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-263-91be3d937749>\", line 9, in <module>\n    x = tf.placeholder(tf.float32, shape = (None, n_inputs), name = 'X')\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1530, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 1954, in _placeholder\n    name=name)\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Shape [-1,4] has negative dimensions\n\t [[Node: X_1 = Placeholder[dtype=DT_FLOAT, shape=[?,4], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 40\n",
    "batch_size = 200\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    start, stop = 0,0\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(x_train.shape[0]//batch_size):\n",
    "            stop = start + batch_size\n",
    "            x_batch, y_batch = x_train[start:stop], y_train[start:stop]\n",
    "            sess.run(training_op, feed_dict = {X:x_batch, y:y_batch})\n",
    "            start = stop+ 1\n",
    "        acc_train = accuracy.eval(feed_dict = {X: x_batch, y: y_batch})\n",
    "        acc_val = accuracy.eval(feed_dict = {X: x_val, y: y_val})\n",
    "        print(epoch, 'Train accuracy: ', acc_train, 'val_accuracy: ', acc_val)\n",
    "    import os\n",
    "    cwd = os.getcwd() + '/my_model_final.ckpt'\n",
    "    save_path = saver.save(sess, cwd)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    cwd = os.getcwd() + '/my_model_final.ckpt'\n",
    "    saver.restore(sess, cwd)\n",
    "    z = logits.eval(feed_dict = {X:test_x})\n",
    "    y_pred = np.argmax(z, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95757, 4)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPECIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "softmax() got an unexpected keyword argument 'axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-333-b9c9152c0837>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# output layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'rmsprop'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    179\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m             \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[1;32mC:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m             \u001b[1;31m# Actually call the layer,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[1;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    881\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'channels_last'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 883\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    884\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    885\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\keras\\activations.py\u001b[0m in \u001b[0;36msoftmax\u001b[1;34m(x, axis)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cannot apply softmax to a tensor that is 1D'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0me\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36msoftmax\u001b[1;34m(x, axis)\u001b[0m\n\u001b[0;32m   3229\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3230\u001b[0m     \"\"\"\n\u001b[1;32m-> 3231\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: softmax() got an unexpected keyword argument 'axis'"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "#x_val, test_x, y_val, test_y\n",
    "model = models.Sequential()\n",
    "# input layer\n",
    "model.add(layers.Dense(20, activation = 'relu', input_shape = (4,)))\n",
    "# hidden layers\n",
    "model.add(layers.Dropout(0.3, noise_shape = None, seed = None))\n",
    "model.add(layers.Dense(20, activation = 'relu'))\n",
    "model.add(layers.Dropout(0.2, noise_shape = None, seed = None))\n",
    "model.add(layers.Dense(30, activation = 'relu'))\n",
    "\n",
    "# output layer \n",
    "model.add(layers.Dense(1, activation = 'softmax'))\n",
    "model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_9_input to have 3 dimensions, but got array with shape (95757, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-332-10c71782157e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m8000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    953\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    126\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    129\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected dense_9_input to have 3 dimensions, but got array with shape (95757, 4)"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs = 20, batch_size = 8000, validation_data = (x_val, test_x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 95757 and 200 for 'truediv_4' (op: 'RealDiv') with input shapes: [95757,4], [200,4].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[0;32m    670\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[0;32m    672\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\INVENTAR\\Anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 95757 and 200 for 'truediv_4' (op: 'RealDiv') with input shapes: [95757,4], [200,4].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-319-cf9b2b63ce86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# scale units\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# maximum of X array\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m100\u001b[0m \u001b[1;31m# max test score is 100\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mr_binary_op_wrapper\u001b[1;34m(y, x)\u001b[0m\n\u001b[0;32m    852\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"x\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 854\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m   \u001b[1;31m# Propagate func.__doc__ to the wrappers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m_truediv_python3\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_real_div\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36m_real_div\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1718\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1719\u001b[0m   \"\"\"\n\u001b[1;32m-> 1720\u001b[1;33m   \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op_def_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"RealDiv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1721\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1722\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    765\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    766\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    768\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   2506\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[0;32m   2507\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2508\u001b[1;33m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2509\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2510\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1871\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1872\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1873\u001b[1;33m   \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1874\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1875\u001b[0m     raise RuntimeError(\n",
      "\u001b[1;32mC:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1821\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[0;32m    608\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[0;32m    609\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m                                   debug_python_shape_fn, require_shape_fn)\n\u001b[0m\u001b[0;32m    611\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m       \u001b[1;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[0;32m    674\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimensions must be equal, but are 95757 and 200 for 'truediv_4' (op: 'RealDiv') with input shapes: [95757,4], [200,4]."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# X = (hours sleeping, hours studying), y = score on test\n",
    "#X = np.array(([2, 9], [1, 5], [3, 6]), dtype=float)\n",
    "#y = np.array(([92], [86], [89]), dtype=float)\n",
    "\n",
    "# scale units\n",
    "X = x_train/np.amax(X, axis=0) # maximum of X array\n",
    "y = y_train/100 # max test score is 100\n",
    "\n",
    "class Neural_Network(object):\n",
    "      def __init__(self):\n",
    "        #parameters\n",
    "        self.inputSize = 4\n",
    "        self.outputSize = 1\n",
    "        self.hiddenSize = 3\n",
    "\n",
    "        #weights\n",
    "        self.W1 = np.random.randn(self.inputSize, self.hiddenSize) # (3x2) weight matrix from input to hidden layer\n",
    "        self.W2 = np.random.randn(self.hiddenSize, self.outputSize) # (3x1) weight matrix from hidden to output layer\n",
    "        return\n",
    "\n",
    "      def forward(self, X):\n",
    "        #forward propagation through our network\n",
    "        self.z = np.dot(X, self.W1) # dot product of X (input) and first set of 3x2 weights\n",
    "        self.z2 = self.sigmoid(self.z) # activation function\n",
    "        self.z3 = np.dot(self.z2, self.W2) # dot product of hidden layer (z2) and second set of 3x1 weights\n",
    "        o = self.sigmoid(self.z3) # final activation function\n",
    "        return o\n",
    "\n",
    "      def sigmoid(self, s):\n",
    "        # activation function\n",
    "        return 1/(1+np.exp(-s))\n",
    "\n",
    "NN = Neural_Network()\n",
    "\n",
    "#defining our output\n",
    "o = NN.forward(X)\n",
    "\n",
    "print (\"Predicted Output: \\n\" + str(o))\n",
    "print (\"Actual Output: \\n\" + str(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fine_tune Neural network model using randomized search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on MLPClassifier in module sklearn.neural_network.multilayer_perceptron object:\n",
      "\n",
      "class MLPClassifier(BaseMultilayerPerceptron, sklearn.base.ClassifierMixin)\n",
      " |  Multi-layer Perceptron classifier.\n",
      " |  \n",
      " |  This model optimizes the log-loss function using LBFGS or stochastic\n",
      " |  gradient descent.\n",
      " |  \n",
      " |  .. versionadded:: 0.18\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  hidden_layer_sizes : tuple, length = n_layers - 2, default (100,)\n",
      " |      The ith element represents the number of neurons in the ith\n",
      " |      hidden layer.\n",
      " |  \n",
      " |  activation : {'identity', 'logistic', 'tanh', 'relu'}, default 'relu'\n",
      " |      Activation function for the hidden layer.\n",
      " |  \n",
      " |      - 'identity', no-op activation, useful to implement linear bottleneck,\n",
      " |        returns f(x) = x\n",
      " |  \n",
      " |      - 'logistic', the logistic sigmoid function,\n",
      " |        returns f(x) = 1 / (1 + exp(-x)).\n",
      " |  \n",
      " |      - 'tanh', the hyperbolic tan function,\n",
      " |        returns f(x) = tanh(x).\n",
      " |  \n",
      " |      - 'relu', the rectified linear unit function,\n",
      " |        returns f(x) = max(0, x)\n",
      " |  \n",
      " |  solver : {'lbfgs', 'sgd', 'adam'}, default 'adam'\n",
      " |      The solver for weight optimization.\n",
      " |  \n",
      " |      - 'lbfgs' is an optimizer in the family of quasi-Newton methods.\n",
      " |  \n",
      " |      - 'sgd' refers to stochastic gradient descent.\n",
      " |  \n",
      " |      - 'adam' refers to a stochastic gradient-based optimizer proposed\n",
      " |        by Kingma, Diederik, and Jimmy Ba\n",
      " |  \n",
      " |      Note: The default solver 'adam' works pretty well on relatively\n",
      " |      large datasets (with thousands of training samples or more) in terms of\n",
      " |      both training time and validation score.\n",
      " |      For small datasets, however, 'lbfgs' can converge faster and perform\n",
      " |      better.\n",
      " |  \n",
      " |  alpha : float, optional, default 0.0001\n",
      " |      L2 penalty (regularization term) parameter.\n",
      " |  \n",
      " |  batch_size : int, optional, default 'auto'\n",
      " |      Size of minibatches for stochastic optimizers.\n",
      " |      If the solver is 'lbfgs', the classifier will not use minibatch.\n",
      " |      When set to \"auto\", `batch_size=min(200, n_samples)`\n",
      " |  \n",
      " |  learning_rate : {'constant', 'invscaling', 'adaptive'}, default 'constant'\n",
      " |      Learning rate schedule for weight updates.\n",
      " |  \n",
      " |      - 'constant' is a constant learning rate given by\n",
      " |        'learning_rate_init'.\n",
      " |  \n",
      " |      - 'invscaling' gradually decreases the learning rate ``learning_rate_``\n",
      " |        at each time step 't' using an inverse scaling exponent of 'power_t'.\n",
      " |        effective_learning_rate = learning_rate_init / pow(t, power_t)\n",
      " |  \n",
      " |      - 'adaptive' keeps the learning rate constant to\n",
      " |        'learning_rate_init' as long as training loss keeps decreasing.\n",
      " |        Each time two consecutive epochs fail to decrease training loss by at\n",
      " |        least tol, or fail to increase validation score by at least tol if\n",
      " |        'early_stopping' is on, the current learning rate is divided by 5.\n",
      " |  \n",
      " |      Only used when ``solver='sgd'``.\n",
      " |  \n",
      " |  max_iter : int, optional, default 200\n",
      " |      Maximum number of iterations. The solver iterates until convergence\n",
      " |      (determined by 'tol') or this number of iterations.\n",
      " |  \n",
      " |  random_state : int or RandomState, optional, default None\n",
      " |      State or seed for random number generator.\n",
      " |  \n",
      " |  shuffle : bool, optional, default True\n",
      " |      Whether to shuffle samples in each iteration. Only used when\n",
      " |      solver='sgd' or 'adam'.\n",
      " |  \n",
      " |  tol : float, optional, default 1e-4\n",
      " |      Tolerance for the optimization. When the loss or score is not improving\n",
      " |      by at least tol for two consecutive iterations, unless `learning_rate`\n",
      " |      is set to 'adaptive', convergence is considered to be reached and\n",
      " |      training stops.\n",
      " |  \n",
      " |  learning_rate_init : double, optional, default 0.001\n",
      " |      The initial learning rate used. It controls the step-size\n",
      " |      in updating the weights. Only used when solver='sgd' or 'adam'.\n",
      " |  \n",
      " |  power_t : double, optional, default 0.5\n",
      " |      The exponent for inverse scaling learning rate.\n",
      " |      It is used in updating effective learning rate when the learning_rate\n",
      " |      is set to 'invscaling'. Only used when solver='sgd'.\n",
      " |  \n",
      " |  verbose : bool, optional, default False\n",
      " |      Whether to print progress messages to stdout.\n",
      " |  \n",
      " |  warm_start : bool, optional, default False\n",
      " |      When set to True, reuse the solution of the previous\n",
      " |      call to fit as initialization, otherwise, just erase the\n",
      " |      previous solution.\n",
      " |  \n",
      " |  momentum : float, default 0.9\n",
      " |      Momentum for gradient descent update. Should be between 0 and 1. Only\n",
      " |      used when solver='sgd'.\n",
      " |  \n",
      " |  nesterovs_momentum : boolean, default True\n",
      " |      Whether to use Nesterov's momentum. Only used when solver='sgd' and\n",
      " |      momentum > 0.\n",
      " |  \n",
      " |  early_stopping : bool, default False\n",
      " |      Whether to use early stopping to terminate training when validation\n",
      " |      score is not improving. If set to true, it will automatically set\n",
      " |      aside 10% of training data as validation and terminate training when\n",
      " |      validation score is not improving by at least tol for two consecutive\n",
      " |      epochs.\n",
      " |      Only effective when solver='sgd' or 'adam'\n",
      " |  \n",
      " |  validation_fraction : float, optional, default 0.1\n",
      " |      The proportion of training data to set aside as validation set for\n",
      " |      early stopping. Must be between 0 and 1.\n",
      " |      Only used if early_stopping is True\n",
      " |  \n",
      " |  beta_1 : float, optional, default 0.9\n",
      " |      Exponential decay rate for estimates of first moment vector in adam,\n",
      " |      should be in [0, 1). Only used when solver='adam'\n",
      " |  \n",
      " |  beta_2 : float, optional, default 0.999\n",
      " |      Exponential decay rate for estimates of second moment vector in adam,\n",
      " |      should be in [0, 1). Only used when solver='adam'\n",
      " |  \n",
      " |  epsilon : float, optional, default 1e-8\n",
      " |      Value for numerical stability in adam. Only used when solver='adam'\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  `classes_` : array or list of array of shape (n_classes,)\n",
      " |      Class labels for each output.\n",
      " |  \n",
      " |  `loss_` : float\n",
      " |      The current loss computed with the loss function.\n",
      " |  \n",
      " |  `coefs_` : list, length n_layers - 1\n",
      " |      The ith element in the list represents the weight matrix corresponding\n",
      " |      to layer i.\n",
      " |  \n",
      " |  `intercepts_` : list, length n_layers - 1\n",
      " |      The ith element in the list represents the bias vector corresponding to\n",
      " |      layer i + 1.\n",
      " |  \n",
      " |  n_iter_ : int,\n",
      " |      The number of iterations the solver has ran.\n",
      " |  \n",
      " |  n_layers_ : int\n",
      " |      Number of layers.\n",
      " |  \n",
      " |  `n_outputs_` : int\n",
      " |      Number of outputs.\n",
      " |  \n",
      " |  `out_activation_` : string\n",
      " |      Name of the output activation function.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  MLPClassifier trains iteratively since at each time step\n",
      " |  the partial derivatives of the loss function with respect to the model\n",
      " |  parameters are computed to update the parameters.\n",
      " |  \n",
      " |  It can also have a regularization term added to the loss function\n",
      " |  that shrinks model parameters to prevent overfitting.\n",
      " |  \n",
      " |  This implementation works with data represented as dense numpy arrays or\n",
      " |  sparse scipy arrays of floating point values.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  Hinton, Geoffrey E.\n",
      " |      \"Connectionist learning procedures.\" Artificial intelligence 40.1\n",
      " |      (1989): 185-234.\n",
      " |  \n",
      " |  Glorot, Xavier, and Yoshua Bengio. \"Understanding the difficulty of\n",
      " |      training deep feedforward neural networks.\" International Conference\n",
      " |      on Artificial Intelligence and Statistics. 2010.\n",
      " |  \n",
      " |  He, Kaiming, et al. \"Delving deep into rectifiers: Surpassing human-level\n",
      " |      performance on imagenet classification.\" arXiv preprint\n",
      " |      arXiv:1502.01852 (2015).\n",
      " |  \n",
      " |  Kingma, Diederik, and Jimmy Ba. \"Adam: A method for stochastic\n",
      " |      optimization.\" arXiv preprint arXiv:1412.6980 (2014).\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      MLPClassifier\n",
      " |      BaseMultilayerPerceptron\n",
      " |      abc.NewBase\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, hidden_layer_sizes=(100,), activation='relu', solver='adam', alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict using the multi-layer perceptron classifier\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : array-like, shape (n_samples,) or (n_samples, n_classes)\n",
      " |          The predicted classes.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Return the log of probability estimates.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      log_y_prob : array-like, shape (n_samples, n_classes)\n",
      " |          The predicted log-probability of the sample for each class\n",
      " |          in the model, where classes are ordered as they are in\n",
      " |          `self.classes_`. Equivalent to log(predict_proba(X))\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Probability estimates.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_prob : array-like, shape (n_samples, n_classes)\n",
      " |          The predicted probability of the sample for each class in the\n",
      " |          model, where classes are ordered as they are in `self.classes_`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  partial_fit\n",
      " |      Fit the model to data matrix X and target y.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          The target values.\n",
      " |      \n",
      " |      classes : array, shape (n_classes)\n",
      " |          Classes across all calls to partial_fit.\n",
      " |          Can be obtained via `np.unique(y_all)`, where y_all is the\n",
      " |          target vector of the entire dataset.\n",
      " |          This argument is required for the first call to partial_fit\n",
      " |          and can be omitted in the subsequent calls.\n",
      " |          Note that y doesn't need to contain all labels in `classes`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : returns a trained MLP model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseMultilayerPerceptron:\n",
      " |  \n",
      " |  fit(self, X, y)\n",
      " |      Fit the model to data matrix X and target y.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          The target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : returns a trained MLP model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.84502438464 0.847209386112\n",
      "4 0.843739883246 0.846050220085\n",
      "5 0.848094656265 0.849825341876\n",
      "6 0.847582944328 0.849559046978\n",
      "7 0.84761427363 0.849042121587\n",
      "8 0.847645602932 0.848854148718\n",
      "9 0.847113004793 0.849433731731\n",
      "10 0.847676932235 0.849183101239\n",
      "11 0.847927566653 0.84910477921\n",
      "12 0.848627254404 0.853381161986\n",
      "13 0.848481050994 0.853443819609\n",
      "14 0.848366176885 0.852989551841\n"
     ]
    }
   ],
   "source": [
    "def best_feature_number(x, y, n_default):\n",
    "    for i in range(3,n_default):\n",
    "        test = SelectKBest(score_func =chi2, k = i)\n",
    "        fit = test.fit(x,y)\n",
    "        # summarize scores\n",
    "        np.set_printoptions(precision = 3)\n",
    "        features = fit.transform(x)\n",
    "        \n",
    "        from sklearn.preprocessing import MinMaxScaler\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        from sklearn.preprocessing import Normalizer\n",
    "        min_max = MinMaxScaler()\n",
    "        std = StandardScaler()\n",
    "        norm = Normalizer()\n",
    "\n",
    "        x_new = min_max.fit_transform(features)\n",
    "        x_std = std.fit_transform(x_new)\n",
    "        x_norm = std.fit_transform(x_std)\n",
    "        \n",
    "        from sklearn.model_selection import train_test_split\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x_norm, y, test_size = 0.4, random_state = 42)\n",
    "\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        log = LogisticRegression()\n",
    "        \n",
    "        log.fit(x_train, y_train)\n",
    "        value = log.score(x_train, y_train)\n",
    "\n",
    "        prediction = log.predict(x_test)\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        solution = accuracy_score(prediction, y_test)\n",
    "        print(i, value,solution)\n",
    "        \n",
    "    return \n",
    "best_feature_number(x, target, n_default = 15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# recursive feature elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 3\n",
      "Selected Features: [False False False False False False False False False  True  True  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False]\n",
      "Feature Ranking: [51  4 50 39 53 45 48 38  3  1  1  1  2 19 28 29 24 59 16 18 57 20 23 31 60\n",
      " 26 43 37 36 54 56 30 22 62  5 41 49 27 64 34 17 33 63 40 46 42 25 32 58 44\n",
      " 61 55 65 47 35 21 52 14 13 12 15 11  6 10  9  8  7]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "# feature extraction\n",
    "model = LogisticRegression()\n",
    "rfe = RFE(model, 3)\n",
    "fit = rfe.fit(x, target)\n",
    "print('Num Features: %d' % fit.n_features_)\n",
    "print('Selected Features: %s' % fit.support_)\n",
    "print('Feature Ranking: %s' % fit.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paymentRatio\n",
      "FirstPaymentDefault\n",
      "clientGender_FEMALE\n"
     ]
    }
   ],
   "source": [
    "for i, j in zip(fit.support_, x.columns):\n",
    "    if i == True:\n",
    "        print(j)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_feature = x[['paymentRatio', 'FirstPaymentDefault','clientGender_FEMALE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84589839344344475"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(new_feature, target)\n",
    "model.score(new_feature, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84502438464 0.847209386112\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(new_feature, target, test_size = 0.4, random_state = 42)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log = LogisticRegression()\n",
    "        \n",
    "log.fit(x_train, y_train)\n",
    "value = log.score(x_train, y_train)\n",
    "\n",
    "prediction = log.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "solution = accuracy_score(prediction, y_test)\n",
    "print(value, solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance sum: 0.999999998299\n",
      "[[  9.961e-01   4.229e-07   1.301e-05   4.636e-08   8.852e-02  -6.524e-06\n",
      "    3.634e-05   1.618e-07  -1.899e-07  -4.987e-08  -2.082e-07  -3.738e-07\n",
      "    3.738e-07  -2.603e-09   1.280e-07  -7.223e-09  -1.208e-08  -7.107e-09\n",
      "   -1.228e-09  -5.389e-09  -2.191e-08   1.123e-09  -8.402e-09  -4.913e-09\n",
      "   -5.113e-09  -1.553e-08  -1.431e-08   4.734e-09  -3.718e-09  -3.037e-09\n",
      "   -8.295e-10  -1.794e-08   3.070e-09  -1.558e-09  -3.494e-09  -1.182e-08\n",
      "   -2.956e-08   1.947e-07  -3.320e-11  -1.867e-08  -8.286e-09  -1.107e-07\n",
      "   -2.167e-11  -3.031e-08  -1.334e-08  -3.127e-08  -1.535e-08   8.510e-08\n",
      "   -4.632e-09  -4.561e-09  -1.697e-10  -1.588e-09   2.642e-11   7.972e-07\n",
      "    1.020e-08  -8.105e-07   3.080e-09   1.865e-07  -1.003e-07  -3.599e-08\n",
      "   -4.188e-08  -8.276e-09  -6.216e-08  -3.255e-07   5.195e-07  -1.250e-07\n",
      "   -6.850e-09]\n",
      " [ -8.852e-02   5.363e-06   2.593e-05   2.227e-05   9.961e-01  -1.021e-04\n",
      "    1.010e-03   3.759e-07   2.772e-07  -5.188e-07  -1.000e-06   9.191e-08\n",
      "   -9.191e-08  -3.468e-08   3.335e-07   1.522e-09  -1.998e-08  -1.783e-08\n",
      "    4.891e-09   9.442e-09  -4.946e-08  -9.471e-09   3.616e-09  -7.356e-08\n",
      "   -5.114e-09  -2.479e-08  -5.470e-08  -1.670e-08  -1.967e-09  -3.088e-08\n",
      "   -2.973e-09   2.739e-08   9.666e-09  -3.552e-09   1.367e-08  -5.190e-08\n",
      "   -5.974e-08   5.563e-07   5.538e-10  -4.021e-09  -3.691e-08  -1.392e-07\n",
      "    6.023e-10  -6.915e-08  -1.108e-07  -1.986e-07   3.083e-08   1.972e-08\n",
      "    4.484e-09  -5.812e-09   5.074e-09   4.387e-10  -2.453e-10   1.410e-06\n",
      "    4.390e-08  -1.483e-06   2.975e-08   1.872e-07   2.091e-07   1.987e-07\n",
      "   -3.245e-07  -2.704e-07   4.236e-08  -3.286e-07  -1.178e-07   4.201e-07\n",
      "   -1.604e-08]\n",
      " [ -5.327e-05  -1.964e-03   2.717e-03  -1.052e-02   1.014e-03   6.806e-02\n",
      "   -9.976e-01   3.165e-03  -1.035e-03   3.293e-04   4.602e-04   3.636e-05\n",
      "   -3.636e-05  -7.901e-06   2.710e-05  -1.362e-06  -1.091e-05  -4.301e-06\n",
      "    4.538e-06   1.775e-05   9.706e-07  -6.671e-07   1.187e-05  -2.461e-05\n",
      "   -3.171e-06  -2.011e-05   1.897e-05  -8.887e-07   4.082e-07   1.740e-05\n",
      "    2.301e-06  -1.356e-05  -5.930e-06   4.909e-06   6.059e-06   1.558e-05\n",
      "   -3.526e-06  -1.177e-04  -2.550e-07   8.153e-06   2.995e-05   2.326e-05\n",
      "   -2.090e-07  -3.791e-07   1.742e-05   5.055e-06   3.332e-06  -1.573e-05\n",
      "    3.619e-06   6.256e-06   1.222e-06   5.067e-06   1.540e-07   1.554e-04\n",
      "    1.244e-05  -1.908e-04   2.282e-05  -3.382e-04   1.041e-04   2.564e-05\n",
      "    7.293e-06   2.012e-04   1.501e-06  -1.637e-04   4.299e-05   9.814e-05\n",
      "    2.102e-05]\n",
      " [ -1.064e-05   2.661e-03   9.962e-01  -2.605e-02  -3.156e-05  -6.265e-02\n",
      "   -1.272e-03   1.691e-03  -1.121e-04  -1.540e-03  -3.286e-03  -4.560e-03\n",
      "    4.560e-03  -1.290e-04   1.113e-04  -2.810e-05   1.163e-05  -3.858e-04\n",
      "   -3.649e-05  -3.338e-05  -4.265e-05  -6.410e-05  -2.255e-04  -5.268e-05\n",
      "   -8.875e-05  -3.836e-04  -5.633e-05  -4.116e-04  -3.040e-05  -2.595e-04\n",
      "   -1.275e-05   1.687e-04  -8.968e-05  -1.903e-05  -5.664e-05   8.016e-05\n",
      "   -2.169e-04   1.569e-04   2.055e-06   1.413e-04   6.811e-05   1.406e-03\n",
      "    1.022e-06   2.158e-05  -2.224e-04   7.354e-04  -9.976e-05   6.124e-05\n",
      "   -1.431e-05   1.398e-05  -2.202e-05   1.786e-06   4.243e-06   3.626e-02\n",
      "    1.220e-03  -3.840e-02   9.230e-04  -1.952e-03   2.930e-03   1.672e-03\n",
      "   -1.466e-03  -1.184e-03  -6.866e-04  -9.909e-03   8.825e-03   1.861e-03\n",
      "   -9.011e-05]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# feature extraction\n",
    "pca = PCA(n_components = 4)\n",
    "fit = pca.fit(x)\n",
    "# summarize components\n",
    "print('Explained Variance sum: %s' % fit.explained_variance_ratio_.sum())\n",
    "print(fit.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 67)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.components_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.394  0.605  0.001]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(new_feature, target)\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.109  0.06   0.372  0.459]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(x_norm, target)\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84605022008490105"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(prediction, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41913  4045]\n",
      " [ 5783 12098]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_test, prediction)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71114507406536553"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.91      0.90     45958\n",
      "          1       0.75      0.68      0.71     17881\n",
      "\n",
      "avg / total       0.84      0.85      0.84     63839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function heatmap in module seaborn.matrix:\n",
      "\n",
      "heatmap(data, vmin=None, vmax=None, cmap=None, center=None, robust=False, annot=None, fmt='.2g', annot_kws=None, linewidths=0, linecolor='white', cbar=True, cbar_kws=None, cbar_ax=None, square=False, ax=None, xticklabels=True, yticklabels=True, mask=None, **kwargs)\n",
      "    Plot rectangular data as a color-encoded matrix.\n",
      "    \n",
      "    This function tries to infer a good colormap to use from the data, but\n",
      "    this is not guaranteed to work, so take care to make sure the kind of\n",
      "    colormap (sequential or diverging) and its limits are appropriate.\n",
      "    \n",
      "    This is an Axes-level function and will draw the heatmap into the\n",
      "    currently-active Axes if none is provided to the ``ax`` argument.  Part of\n",
      "    this Axes space will be taken and used to plot a colormap, unless ``cbar``\n",
      "    is False or a separate Axes is provided to ``cbar_ax``.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    data : rectangular dataset\n",
      "        2D dataset that can be coerced into an ndarray. If a Pandas DataFrame\n",
      "        is provided, the index/column information will be used to label the\n",
      "        columns and rows.\n",
      "    vmin, vmax : floats, optional\n",
      "        Values to anchor the colormap, otherwise they are inferred from the\n",
      "        data and other keyword arguments. When a diverging dataset is inferred,\n",
      "        one of these values may be ignored.\n",
      "    cmap : matplotlib colormap name or object, optional\n",
      "        The mapping from data values to color space. If not provided, this\n",
      "        will be either a cubehelix map (if the function infers a sequential\n",
      "        dataset) or ``RdBu_r`` (if the function infers a diverging dataset).\n",
      "    center : float, optional\n",
      "        The value at which to center the colormap. Passing this value implies\n",
      "        use of a diverging colormap.\n",
      "    robust : bool, optional\n",
      "        If True and ``vmin`` or ``vmax`` are absent, the colormap range is\n",
      "        computed with robust quantiles instead of the extreme values.\n",
      "    annot : bool or rectangular dataset, optional\n",
      "        If True, write the data value in each cell. If an array-like with the\n",
      "        same shape as ``data``, then use this to annotate the heatmap instead\n",
      "        of the raw data.\n",
      "    fmt : string, optional\n",
      "        String formatting code to use when adding annotations.\n",
      "    annot_kws : dict of key, value mappings, optional\n",
      "        Keyword arguments for ``ax.text`` when ``annot`` is True.\n",
      "    linewidths : float, optional\n",
      "        Width of the lines that will divide each cell.\n",
      "    linecolor : color, optional\n",
      "        Color of the lines that will divide each cell.\n",
      "    cbar : boolean, optional\n",
      "        Whether to draw a colorbar.\n",
      "    cbar_kws : dict of key, value mappings, optional\n",
      "        Keyword arguments for `fig.colorbar`.\n",
      "    cbar_ax : matplotlib Axes, optional\n",
      "        Axes in which to draw the colorbar, otherwise take space from the\n",
      "        main Axes.\n",
      "    square : boolean, optional\n",
      "        If True, set the Axes aspect to \"equal\" so each cell will be\n",
      "        square-shaped.\n",
      "    ax : matplotlib Axes, optional\n",
      "        Axes in which to draw the plot, otherwise use the currently-active\n",
      "        Axes.\n",
      "    xticklabels : list-like, int, or bool, optional\n",
      "        If True, plot the column names of the dataframe. If False, don't plot\n",
      "        the column names. If list-like, plot these alternate labels as the\n",
      "        xticklabels. If an integer, use the column names but plot only every\n",
      "        n label.\n",
      "    yticklabels : list-like, int, or bool, optional\n",
      "        If True, plot the row names of the dataframe. If False, don't plot\n",
      "        the row names. If list-like, plot these alternate labels as the\n",
      "        yticklabels. If an integer, use the index names but plot only every\n",
      "        n label.\n",
      "    mask : boolean array or DataFrame, optional\n",
      "        If passed, data will not be shown in cells where ``mask`` is True.\n",
      "        Cells with missing values are automatically masked.\n",
      "    kwargs : other keyword arguments\n",
      "        All other keyword arguments are passed to ``ax.pcolormesh``.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    ax : matplotlib Axes\n",
      "        Axes object with the heatmap.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    \n",
      "    Plot a heatmap for a numpy array:\n",
      "    \n",
      "    .. plot::\n",
      "        :context: close-figs\n",
      "    \n",
      "        >>> import numpy as np; np.random.seed(0)\n",
      "        >>> import seaborn as sns; sns.set()\n",
      "        >>> uniform_data = np.random.rand(10, 12)\n",
      "        >>> ax = sns.heatmap(uniform_data)\n",
      "    \n",
      "    Change the limits of the colormap:\n",
      "    \n",
      "    .. plot::\n",
      "        :context: close-figs\n",
      "    \n",
      "        >>> ax = sns.heatmap(uniform_data, vmin=0, vmax=1)\n",
      "    \n",
      "    Plot a heatmap for data centered on 0:\n",
      "    \n",
      "    .. plot::\n",
      "        :context: close-figs\n",
      "    \n",
      "        >>> normal_data = np.random.randn(10, 12)\n",
      "        >>> ax = sns.heatmap(normal_data)\n",
      "    \n",
      "    Plot a dataframe with meaningful row and column labels:\n",
      "    \n",
      "    .. plot::\n",
      "        :context: close-figs\n",
      "    \n",
      "        >>> flights = sns.load_dataset(\"flights\")\n",
      "        >>> flights = flights.pivot(\"month\", \"year\", \"passengers\")\n",
      "        >>> ax = sns.heatmap(flights)\n",
      "    \n",
      "    Annotate each cell with the numeric value using integer formatting:\n",
      "    \n",
      "    .. plot::\n",
      "        :context: close-figs\n",
      "    \n",
      "        >>> ax = sns.heatmap(flights, annot=True, fmt=\"d\")\n",
      "    \n",
      "    Add lines between each cell:\n",
      "    \n",
      "    .. plot::\n",
      "        :context: close-figs\n",
      "    \n",
      "        >>> ax = sns.heatmap(flights, linewidths=.5)\n",
      "    \n",
      "    Use a different colormap:\n",
      "    \n",
      "    .. plot::\n",
      "        :context: close-figs\n",
      "    \n",
      "        >>> ax = sns.heatmap(flights, cmap=\"YlGnBu\")\n",
      "    \n",
      "    Center the colormap at a specific value:\n",
      "    \n",
      "    .. plot::\n",
      "        :context: close-figs\n",
      "    \n",
      "        >>> ax = sns.heatmap(flights, center=flights.loc[\"January\", 1955])\n",
      "    \n",
      "    Plot every other column label and don't plot row labels:\n",
      "    \n",
      "    .. plot::\n",
      "        :context: close-figs\n",
      "    \n",
      "        >>> data = np.random.randn(50, 20)\n",
      "        >>> ax = sns.heatmap(data, xticklabels=2, yticklabels=False)\n",
      "    \n",
      "    Don't draw a colorbar:\n",
      "    \n",
      "    .. plot::\n",
      "        :context: close-figs\n",
      "    \n",
      "        >>> ax = sns.heatmap(flights, cbar=False)\n",
      "    \n",
      "    Use different axes for the colorbar:\n",
      "    \n",
      "    .. plot::\n",
      "        :context: close-figs\n",
      "    \n",
      "        >>> grid_kws = {\"height_ratios\": (.9, .05), \"hspace\": .3}\n",
      "        >>> f, (ax, cbar_ax) = plt.subplots(2, gridspec_kw=grid_kws)\n",
      "        >>> ax = sns.heatmap(flights, ax=ax,\n",
      "        ...                  cbar_ax=cbar_ax,\n",
      "        ...                  cbar_kws={\"orientation\": \"horizontal\"})\n",
      "    \n",
      "    Use a mask to plot only part of a matrix\n",
      "    \n",
      "    .. plot::\n",
      "        :context: close-figs\n",
      "    \n",
      "        >>> corr = np.corrcoef(np.random.randn(10, 200))\n",
      "        >>> mask = np.zeros_like(corr)\n",
      "        >>> mask[np.triu_indices_from(mask)] = True\n",
      "        >>> with sns.axes_style(\"white\"):\n",
      "        ...     ax = sns.heatmap(corr, mask=mask, vmax=.3, square=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sns.heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clientIncome</th>\n",
       "      <th>incomeVerified</th>\n",
       "      <th>clientAge</th>\n",
       "      <th>loanNumber</th>\n",
       "      <th>loanAmount</th>\n",
       "      <th>interestRate</th>\n",
       "      <th>loanTerm</th>\n",
       "      <th>max_amount_taken</th>\n",
       "      <th>max_tenor_taken</th>\n",
       "      <th>paymentRatio</th>\n",
       "      <th>...</th>\n",
       "      <th>clientLoanPurpose_business</th>\n",
       "      <th>clientLoanPurpose_education</th>\n",
       "      <th>clientLoanPurpose_house</th>\n",
       "      <th>clientLoanPurpose_medical</th>\n",
       "      <th>clientLoanPurpose_other</th>\n",
       "      <th>clientResidentialStauts_Employer Provided</th>\n",
       "      <th>clientResidentialStauts_Family Owned</th>\n",
       "      <th>clientResidentialStauts_Own Residence</th>\n",
       "      <th>clientResidentialStauts_Rented</th>\n",
       "      <th>clientResidentialStauts_Temp. Residence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>48000</td>\n",
       "      <td>7.5</td>\n",
       "      <td>180</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>31500</td>\n",
       "      <td>12.5</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   clientIncome incomeVerified  clientAge  loanNumber  loanAmount  \\\n",
       "0       25000.0              1         38           4       48000   \n",
       "1      105000.0              0         31           4       31500   \n",
       "\n",
       "   interestRate  loanTerm  max_amount_taken  max_tenor_taken  paymentRatio  \\\n",
       "0           7.5       180                 1                1           0.0   \n",
       "1          12.5        90                 1                1           0.0   \n",
       "\n",
       "                    ...                     clientLoanPurpose_business  \\\n",
       "0                   ...                                              1   \n",
       "1                   ...                                              0   \n",
       "\n",
       "   clientLoanPurpose_education  clientLoanPurpose_house  \\\n",
       "0                            0                        0   \n",
       "1                            0                        1   \n",
       "\n",
       "   clientLoanPurpose_medical  clientLoanPurpose_other  \\\n",
       "0                          0                        0   \n",
       "1                          0                        0   \n",
       "\n",
       "   clientResidentialStauts_Employer Provided  \\\n",
       "0                                          0   \n",
       "1                                          0   \n",
       "\n",
       "   clientResidentialStauts_Family Owned  \\\n",
       "0                                     0   \n",
       "1                                     0   \n",
       "\n",
       "   clientResidentialStauts_Own Residence  clientResidentialStauts_Rented  \\\n",
       "0                                      0                               1   \n",
       "1                                      0                               1   \n",
       "\n",
       "   clientResidentialStauts_Temp. Residence  \n",
       "0                                        0  \n",
       "1                                        0  \n",
       "\n",
       "[2 rows x 68 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x['target'] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['clientIncome', 'incomeVerified', 'clientAge', 'loanNumber',\n",
       "       'loanAmount', 'interestRate', 'loanTerm', 'max_amount_taken',\n",
       "       'max_tenor_taken', 'paymentRatio', 'FirstPaymentDefault', 'loanDefault',\n",
       "       'clientGender_FEMALE', 'clientGender_MALE', 'clientState_ABIA',\n",
       "       'clientState_ABUJA', 'clientState_ADAMAWA', 'clientState_AKWA IBOM',\n",
       "       'clientState_ANAMBRA', 'clientState_BAUCHI', 'clientState_BAYELSA',\n",
       "       'clientState_BENUE', 'clientState_BORNO', 'clientState_CROSS RIVER',\n",
       "       'clientState_DELTA', 'clientState_EBONYI', 'clientState_EDO',\n",
       "       'clientState_EKITI', 'clientState_ENUGU', 'clientState_GOMBE',\n",
       "       'clientState_IMO', 'clientState_JIGAWA', 'clientState_KADUNA',\n",
       "       'clientState_KANO', 'clientState_KATSINA', 'clientState_KEBBI',\n",
       "       'clientState_KOGI', 'clientState_KWARA', 'clientState_LAGOS',\n",
       "       'clientState_LAGOS ', 'clientState_NASARAWA', 'clientState_NIGER',\n",
       "       'clientState_OGUN', 'clientState_OJO', 'clientState_ONDO',\n",
       "       'clientState_OSUN', 'clientState_OYO', 'clientState_PLATEAU',\n",
       "       'clientState_RIVERS', 'clientState_SOKOTO', 'clientState_TARABA',\n",
       "       'clientState_YOBE', 'clientState_ZAMFARA',\n",
       "       'clientMaritalStatus_Divorced', 'clientMaritalStatus_Married',\n",
       "       'clientMaritalStatus_Separated', 'clientMaritalStatus_Single',\n",
       "       'clientMaritalStatus_Widowed', 'clientLoanPurpose_business',\n",
       "       'clientLoanPurpose_education', 'clientLoanPurpose_house',\n",
       "       'clientLoanPurpose_medical', 'clientLoanPurpose_other',\n",
       "       'clientResidentialStauts_Employer Provided',\n",
       "       'clientResidentialStauts_Family Owned',\n",
       "       'clientResidentialStauts_Own Residence',\n",
       "       'clientResidentialStauts_Rented',\n",
       "       'clientResidentialStauts_Temp. Residence', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-135-8432834ec8b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'viridis'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\seaborn\\matrix.py\u001b[0m in \u001b[0;36mheatmap\u001b[1;34m(data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, linewidths, linecolor, cbar, cbar_kws, cbar_ax, square, ax, xticklabels, yticklabels, mask, **kwargs)\u001b[0m\n\u001b[0;32m    483\u001b[0m     plotter = _HeatMapper(data, vmin, vmax, cmap, center, robust, annot, fmt,\n\u001b[0;32m    484\u001b[0m                           \u001b[0mannot_kws\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbar_kws\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxticklabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 485\u001b[1;33m                           yticklabels, mask)\n\u001b[0m\u001b[0;32m    486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m     \u001b[1;31m# Add the pcolormesh kwargs here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\seaborn\\matrix.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, cbar, cbar_kws, xticklabels, yticklabels, mask)\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[1;31m# Determine good default values for the colormapping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         self._determine_cmap_params(plot_data, vmin, vmax,\n\u001b[1;32m--> 167\u001b[1;33m                                     cmap, center, robust)\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[1;31m# Sort out the annotations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\seaborn\\matrix.py\u001b[0m in \u001b[0;36m_determine_cmap_params\u001b[1;34m(self, plot_data, vmin, vmax, cmap, center, robust)\u001b[0m\n\u001b[0;32m    202\u001b[0m                                cmap, center, robust):\n\u001b[0;32m    203\u001b[0m         \u001b[1;34m\"\"\"Use some heuristics to set good defaults for colorbar and range.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m         \u001b[0mcalc_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplot_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplot_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvmin\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m             \u001b[0mvmin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcalc_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mrobust\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mcalc_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "sns.heatmap(x, cmap = 'viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
