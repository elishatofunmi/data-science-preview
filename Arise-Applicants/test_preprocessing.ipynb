{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "read_data = pd.read_csv('2019_4_2_02379003-6369-43bf-b444-842420685d06.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['clientId', 'clientIncome', 'incomeVerified', 'clientAge',\n",
       "       'clientGender', 'clientMaritalStatus', 'clientLoanPurpose',\n",
       "       'clientResidentialStauts', 'clientState', 'clientTimeAtEmployer',\n",
       "       'clientNumberPhoneContacts', 'clientAvgCallsPerDay', 'loanType',\n",
       "       'loanNumber', 'applicationDate', 'approvalDate', 'declinedDate',\n",
       "       'disbursementDate', 'payout_status', 'dueDate', 'paidAt', 'loanAmount',\n",
       "       'interestRate', 'loanTerm', 'max_amount_taken', 'max_tenor_taken',\n",
       "       'paymentRatio', 'FirstPaymentDefault', 'loanDefault'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "read_data['incomeVerified'][read_data['incomeVerified'] == 'true'] = 1\n",
    "read_data['incomeVerified'][read_data['incomeVerified'] == 'false'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "read_data = read_data.drop('loanType', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "read_data['clientResidentialStauts'][read_data['clientResidentialStauts']== 'Null'] = 'Rented'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LAGOS          60667\n",
       "OGUN           14798\n",
       "ABUJA          13999\n",
       "OYO            12731\n",
       "RIVERS          7829\n",
       "DELTA           5081\n",
       "KWARA           3969\n",
       "OSUN            3816\n",
       "ONDO            3571\n",
       "KADUNA          3496\n",
       "EDO             2663\n",
       "NIGER           2462\n",
       "BENUE           2043\n",
       "EKITI           2023\n",
       "AKWA IBOM       1960\n",
       "KOGI            1896\n",
       "PLATEAU         1715\n",
       "CROSS RIVER     1608\n",
       "NASARAWA        1589\n",
       "ENUGU           1566\n",
       "ANAMBRA         1496\n",
       "ABIA            1426\n",
       "IMO             1287\n",
       "KANO            1233\n",
       "BAYELSA         1179\n",
       "ADAMAWA          569\n",
       "BAUCHI           418\n",
       "SOKOTO           398\n",
       "EBONYI           392\n",
       "TARABA           336\n",
       "KEBBI            279\n",
       "GOMBE            265\n",
       "KATSINA          248\n",
       "ZAMFARA          221\n",
       "BORNO            210\n",
       "YOBE              83\n",
       "JIGAWA            72\n",
       "OJO                1\n",
       "LAGOS              1\n",
       "Name: clientState, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_data['clientState'][read_data['clientState'] == 'Null'] = 'LAGOS'\n",
    "read_data['clientState'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Married      85492\n",
       "Single       71361\n",
       "Separated     1795\n",
       "Widowed        939\n",
       "Null             6\n",
       "Divorced         3\n",
       "Name: clientMaritalStatus, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_data['clientMaritalStatus'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "read_data['clientMaritalStatus'][read_data['clientMaritalStatus']== 'Null'] = 'Married'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business     78976\n",
       "other        31554\n",
       "house        22240\n",
       "education    15737\n",
       "medical      11089\n",
       "Name: clientLoanPurpose, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_data['clientLoanPurpose'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rented               101670\n",
       "Own Residence         26406\n",
       "Family Owned          25668\n",
       "Employer Provided      5589\n",
       "Temp. Residence         263\n",
       "Name: clientResidentialStauts, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_data['clientResidentialStauts'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.get_dummies(read_data,prefix_sep = '_', columns = ['clientGender', 'clientState', 'clientMaritalStatus',\n",
    "                                         'clientLoanPurpose', 'clientResidentialStauts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clientId</th>\n",
       "      <th>clientIncome</th>\n",
       "      <th>incomeVerified</th>\n",
       "      <th>clientAge</th>\n",
       "      <th>clientTimeAtEmployer</th>\n",
       "      <th>clientNumberPhoneContacts</th>\n",
       "      <th>clientAvgCallsPerDay</th>\n",
       "      <th>loanNumber</th>\n",
       "      <th>applicationDate</th>\n",
       "      <th>approvalDate</th>\n",
       "      <th>...</th>\n",
       "      <th>clientLoanPurpose_business</th>\n",
       "      <th>clientLoanPurpose_education</th>\n",
       "      <th>clientLoanPurpose_house</th>\n",
       "      <th>clientLoanPurpose_medical</th>\n",
       "      <th>clientLoanPurpose_other</th>\n",
       "      <th>clientResidentialStauts_Employer Provided</th>\n",
       "      <th>clientResidentialStauts_Family Owned</th>\n",
       "      <th>clientResidentialStauts_Own Residence</th>\n",
       "      <th>clientResidentialStauts_Rented</th>\n",
       "      <th>clientResidentialStauts_Temp. Residence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>719046128</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>36+</td>\n",
       "      <td>2976</td>\n",
       "      <td>51.40909090909091</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-03-18</td>\n",
       "      <td>2018-03-18</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>821565030</td>\n",
       "      <td>105000.00</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>36+</td>\n",
       "      <td>1159</td>\n",
       "      <td>121.03645833333333</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-01-06</td>\n",
       "      <td>2018-01-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>703822576</td>\n",
       "      <td>78029.19</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>36+</td>\n",
       "      <td>1375</td>\n",
       "      <td>13.402912621359222</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-04-27</td>\n",
       "      <td>2018-04-27</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    clientId  clientIncome incomeVerified  clientAge clientTimeAtEmployer  \\\n",
       "0  719046128      25000.00              1         38                  36+   \n",
       "1  821565030     105000.00              0         31                  36+   \n",
       "2  703822576      78029.19              1         38                  36+   \n",
       "\n",
       "  clientNumberPhoneContacts clientAvgCallsPerDay  loanNumber applicationDate  \\\n",
       "0                      2976    51.40909090909091           4      2018-03-18   \n",
       "1                      1159   121.03645833333333           4      2018-01-06   \n",
       "2                      1375   13.402912621359222           4      2018-04-27   \n",
       "\n",
       "  approvalDate                   ...                     \\\n",
       "0   2018-03-18                   ...                      \n",
       "1   2018-01-06                   ...                      \n",
       "2   2018-04-27                   ...                      \n",
       "\n",
       "  clientLoanPurpose_business clientLoanPurpose_education  \\\n",
       "0                          1                           0   \n",
       "1                          0                           0   \n",
       "2                          0                           1   \n",
       "\n",
       "  clientLoanPurpose_house clientLoanPurpose_medical clientLoanPurpose_other  \\\n",
       "0                       0                         0                       0   \n",
       "1                       1                         0                       0   \n",
       "2                       0                         0                       0   \n",
       "\n",
       "   clientResidentialStauts_Employer Provided  \\\n",
       "0                                          0   \n",
       "1                                          0   \n",
       "2                                          0   \n",
       "\n",
       "   clientResidentialStauts_Family Owned  \\\n",
       "0                                     0   \n",
       "1                                     0   \n",
       "2                                     1   \n",
       "\n",
       "   clientResidentialStauts_Own Residence  clientResidentialStauts_Rented  \\\n",
       "0                                      0                               1   \n",
       "1                                      0                               1   \n",
       "2                                      0                               0   \n",
       "\n",
       "   clientResidentialStauts_Temp. Residence  \n",
       "0                                        0  \n",
       "1                                        0  \n",
       "2                                        0  \n",
       "\n",
       "[3 rows x 79 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.drop(['applicationDate', 'approvalDate', 'declinedDate',\n",
    "       'disbursementDate', 'payout_status', 'dueDate', 'paidAt'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = data.drop(['clientId', 'clientNumberPhoneContacts'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incomeVerified 103\n",
      "clientTimeAtEmployer 159596\n",
      "clientAvgCallsPerDay 159596\n"
     ]
    }
   ],
   "source": [
    "for k in x.columns:\n",
    "    value = sum([isinstance(i, str) for i in x[k]])\n",
    "    if value > 1:\n",
    "        print(k, value)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       133286\n",
       "1        26207\n",
       "Null       103\n",
       "Name: incomeVerified, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['incomeVerified'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x['incomeVerified'][x['incomeVerified']== 'Null'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x['clientTimeAtEmployer'][x['clientTimeAtEmployer']== 'Null'] = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = x.drop(['clientTimeAtEmployer', 'clientAvgCallsPerDay'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'loanDefault' in x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159596,)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = x['loanDefault']\n",
    "x = x.drop('loanDefault', axis = 1)\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "test = SelectKBest(score_func =chi2, k = 10)\n",
    "fit = test.fit(x,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.060e+07   3.275e+02   5.687e+02   1.774e+03   1.050e+06   1.497e+03\n",
      "   2.434e+02   4.778e+02   1.465e+02   4.024e+04   4.386e+04   7.575e+01\n",
      "   3.449e+01   1.218e-02   8.140e+01   1.773e+00   1.658e+00   5.117e+00\n",
      "   2.669e+00   9.298e+00   9.388e+00   2.259e+00   2.538e-01   2.758e+00\n",
      "   4.705e+00   4.986e-01   5.502e+01   1.777e+00   5.008e-01   3.192e+00\n",
      "   1.829e+00   9.236e-01   1.051e+01   1.838e+00   8.678e+00   6.232e+01\n",
      "   6.619e+01   1.533e+02   3.887e-01   8.600e-02   1.393e+02   1.625e+01\n",
      "   2.573e+00   2.665e+01   6.814e+01   1.203e+02   3.348e+00   1.188e+00\n",
      "   3.912e-01   1.611e-02   2.976e-01   7.739e-02   4.251e-02   3.736e+01\n",
      "   3.664e+00   5.172e+01   2.998e+00   4.299e+02   4.079e+01   2.212e+02\n",
      "   1.163e+01   3.178e+02   6.109e+01   1.793e+00   1.464e+01   2.981e-01\n",
      "   3.633e-02]\n"
     ]
    }
   ],
   "source": [
    "# summarize scores\n",
    "np.set_printoptions(precision = 3)\n",
    "print(fit.scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.500e+04   1.000e+00   3.800e+01   4.000e+00   4.800e+04   7.500e+00\n",
      "    1.000e+00   0.000e+00   1.000e+00   1.000e+00]\n",
      " [  1.050e+05   0.000e+00   3.100e+01   4.000e+00   3.150e+04   1.250e+01\n",
      "    1.000e+00   0.000e+00   0.000e+00   0.000e+00]\n",
      " [  7.803e+04   1.000e+00   3.800e+01   4.000e+00   1.295e+05   5.000e+00\n",
      "    1.000e+00   0.000e+00   0.000e+00   0.000e+00]\n",
      " [  3.500e+04   1.000e+00   4.100e+01   3.000e+00   1.750e+04   1.250e+01\n",
      "    1.000e+00   0.000e+00   0.000e+00   0.000e+00]\n",
      " [  3.500e+05   1.000e+00   4.000e+01   2.000e+00   1.325e+05   1.250e+01\n",
      "    1.000e+00   0.000e+00   1.000e+00   1.000e+00]]\n"
     ]
    }
   ],
   "source": [
    "features = fit.transform(x)\n",
    "# summarize selected features\n",
    "print(features[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((159596, 67), (159596, 10))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 2)\n",
    "pmodel = pca.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999991353114015"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "principalDf = pd.DataFrame(data = pmodel, columns = ['principal component 1', 'principal component 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>principal component 1</th>\n",
       "      <th>principal component 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-64458.453741</td>\n",
       "      <td>18454.488372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13766.816133</td>\n",
       "      <td>-5062.749725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4422.734353</td>\n",
       "      <td>94940.114792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-57197.704160</td>\n",
       "      <td>-12811.086747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>266745.894982</td>\n",
       "      <td>73852.253484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   principal component 1  principal component 2\n",
       "0          -64458.453741           18454.488372\n",
       "1           13766.816133           -5062.749725\n",
       "2           -4422.734353           94940.114792\n",
       "3          -57197.704160          -12811.086747\n",
       "4          266745.894982           73852.253484"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display principal components\n",
    "principalDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159596,)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "principalDf['target'] = target"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2 Component PCA', fontsize = 20)\n",
    "\n",
    "\n",
    "targets = [0, 1]\n",
    "colors = ['r', 'g']\n",
    "for target, color in zip(targets,colors):\n",
    "    ax.scatter(principalDf['principal component 1']\n",
    "               , principalDf['principal component 2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "ax.legend(targets)\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_max = MinMaxScaler()\n",
    "std = StandardScaler()\n",
    "norm = Normalizer()\n",
    "\n",
    "x_new = min_max.fit_transform(features)\n",
    "x_std = std.fit_transform(x_new)\n",
    "x_norm = std.fit_transform(x_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159596,)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, target, test_size = 0.4, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_dataframe = pd.DataFrame(x_train)\n",
    "x_test_dataframe = pd.DataFrame(x_test)\n",
    "y_train_dataframe = pd.DataFrame(y_train)\n",
    "y_test_dataframe = pd.DataFrame(y_test)\n",
    "\n",
    "\n",
    "x_train_dataframe.to_csv('x_train.csv')\n",
    "x_test_dataframe.to_csv('x_test.csv')\n",
    "y_train_dataframe.to_csv('y_train.csv')\n",
    "y_test_dataframe.to_csv('y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72023977359357538"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.fit(x_train, y_train)\n",
    "log.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = log.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63839,)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=0, splitter='best')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state = 0)\n",
    "tree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.99679396806499787, 0.71990476041291374)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_score = tree.score(x_train, y_train)\n",
    "prediction = log.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "test_score = accuracy_score(prediction, y_test)\n",
    "train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.847666489134 0.719904760413\n",
      "0.849138966342 0.719904760413\n",
      "0.849149409443 0.719904760413\n",
      "0.850486126341 0.719904760413\n",
      "0.850966508976 0.719904760413\n",
      "0.853243104943 0.719904760413\n",
      "0.854893114864 0.719904760413\n"
     ]
    }
   ],
   "source": [
    "for i in range(3,10):\n",
    "    tree = DecisionTreeClassifier(random_state = 0, max_depth = i)\n",
    "    tree.fit(x_train, y_train)\n",
    "    train_score = tree.score(x_train, y_train)\n",
    "    prediction = log.predict(x_test)\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    test_score = accuracy_score(prediction, y_test)\n",
    "    print(train_score, test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5.508e-03,   0.000e+00,   3.791e-03,   5.851e-03,   4.153e-03,\n",
       "         6.104e-03,   1.104e-02,   1.922e-04,   1.307e-03,   1.708e-01,\n",
       "         7.795e-01,   2.423e-04,   6.501e-04,   3.234e-04,   4.447e-04,\n",
       "         0.000e+00,   1.192e-04,   1.115e-04,   8.175e-05,   2.656e-04,\n",
       "         0.000e+00,   2.967e-04,   0.000e+00,   1.033e-04,   8.176e-05,\n",
       "         2.514e-04,   1.181e-04,   8.397e-05,   4.056e-05,   1.027e-04,\n",
       "         0.000e+00,   1.052e-04,   1.436e-04,   1.466e-04,   5.304e-05,\n",
       "         9.671e-05,   1.299e-04,   0.000e+00,   0.000e+00,   4.631e-05,\n",
       "         1.923e-04,   7.456e-04,   0.000e+00,   4.781e-04,   4.213e-04,\n",
       "         2.775e-04,   3.249e-04,   8.740e-05,   9.937e-05,   1.071e-04,\n",
       "         9.077e-05,   0.000e+00,   0.000e+00,   6.028e-04,   2.328e-04,\n",
       "         2.648e-04,   0.000e+00,   8.129e-04,   8.628e-04,   3.534e-04,\n",
       "         1.807e-04,   6.095e-04,   1.632e-04,   2.478e-04,   3.345e-04,\n",
       "         2.709e-04,   4.930e-05])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=5, n_jobs=1, oob_score=False, random_state=2,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators = 5, random_state = 2)\n",
    "forest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97373560157481964"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83151365152962919"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = forest.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "test_score = accuracy_score(prediction, y_test)\n",
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.996752195662 0.719904760413\n",
      "0.996793968065 0.719904760413\n",
      "0.996793968065 0.719904760413\n",
      "0.996793968065 0.719904760413\n"
     ]
    }
   ],
   "source": [
    "for i in [100,150,200,250]:\n",
    "    tree = RandomForestClassifier(random_state = 0, n_estimators = i)\n",
    "    tree.fit(x_train, y_train)\n",
    "    train_score = tree.score(x_train, y_train)\n",
    "    prediction = log.predict(x_test)\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    test_score = accuracy_score(prediction, y_test)\n",
    "    print(train_score, test_score)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "skfolds = StratifiedKFold(n_splits = 3, random_state = 42)\n",
    "\n",
    "for train_index, test_index in skfolds.split(x_train, y_train):\n",
    "    clone_clf = clone(forest)\n",
    "    x_train_folds = x_train[train_index]\n",
    "    y_train_folds = y_train[train_index]\n",
    "    x_test_fold = x_train[test_index]\n",
    "    y_test_fold = y_train[test_index]\n",
    "    \n",
    "    clone_clf.fit(x_train_folds, y_train_folds)\n",
    "    y_pred = clone_clf.predict(x_test_fold)\n",
    "    n_correct = sum(y_pred == y_test_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.837,  0.837,  0.841,  0.836])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(forest, x_train, y_train, cv = 4, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((63839,), (63839,))"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape, prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEKCAYAAADpfBXhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21ec634f7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, prediction)\n",
    "\n",
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], 'b--', label = 'precision')\n",
    "    plt.plot(thresholds, recalls[:-1], 'g--', label = 'recall')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.legend(loc = 'center left')\n",
    "    plt.ylim([0,1])\n",
    "    plt.show()\n",
    "    \n",
    "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEKCAYAAAAMzhLIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xd4VHXWwPHvSUKAJEBCl25BJJQACVZAEHvBtaCowO4K\nIiKiWNZFRFDWlX0ta0dY1sXCqqvrCioqVixYCEVCEURMQihSkkAKkDLn/WMmwyRAGCAzd2ZyPs+T\nhyk3MyfXOCf3nPs7V1QVY4wx5lCinA7AGGNMaLNEYYwxplqWKIwxxlTLEoUxxphqWaIwxhhTLUsU\nxhhjqhWwRCEiL4rINhFZeYjnRUSeFpH1IrJCRHoFKhZjjDFHL5BHFLOBC6t5/iKgo+drFDA9gLEY\nY4w5SgFLFKr6JZBbzSaXAy+r23dAoogcF6h4jDHGHJ0YB9+7NbDR536O57EtVTcUkVG4jzqIj49P\nPeWUU4ISoDHGhJO9pS6KS8ooKimjeF85JeUuygtzKS/KA9UdqtrsaF7XyUThN1WdCcwESEtL0/T0\ndIcjMsYYZ+0pKWf5xnyWZOWSnpXH0qw8CveWAVAfqKdKQt0YmuVmULbxR76ZNyfraN/LyUSxCWjr\nc7+N5zFjjDFV/LZ7L+mZeSzJymNJVi6rNu+mzFV5Vl+rRvXo0jSGtfOep0fyyTwx+UFiot2tYpE5\nR/3eTiaKecBYEXkdOA3YpaoHlJ2MMaa2KXcp634rID0rjyWZ7iOGnLw9lbaJEujSqiFp7ZNI7dCY\ntPZJfP/5h4wZM4bt27dzTur9xETXTBs6YIlCRF4D+gNNRSQHmAzUAVDVF4D5wMXAeqAY+GOgYjHG\nmFBWXFLG8ux80rPySM/KY1lWHgX7yiptk1A3hp7tEkltn0Ra+8b0aJdIQl33R/hvv/3GbaN+z5tv\nvkmPHj14//336dWr5lYcBCxRqOp1h3legVsD9f7GGBOqtu7aS3pWrreUtHrLbsqrlJFaJ9Z3J4UO\nSaS2T+KUlg2JjpKDvt7GjRt5//33efjhh7nnnnuoU6dOjcYbFs1sY4wJV+UuZe3WAm/TOT0zj035\nlctI0VFCt9aNSG2f5E0OxzWqX+3rZmVl8e677zJ27FjS0tLIzs6mSZMmAfkZLFEYY0wNKtpXxvKN\n+aRn5pGelcvy7PwDykgN6sbQs30SaZ6vlLaJxNf17+PY5XIxffp0/vznPwNw1VVXcdxxxwUsSYAl\nCmOMOSab8/d4T09Nz8plzZaCA8pIbZLqV2o6n9yiwSHLSNVZu3YtI0eO5Ouvv+aCCy5gxowZHHdc\n4NcpW6Iwxhg/lbuUNVt2s8TTdF6SmcvmXXsrbRMdJXRv08jbdE7rkESLhvWO+b2Li4vp06cP5eXl\nzJ49m+HDhyNy5MnmaFiiMMaYQyjcV8ay7Dxv03lZdh5FJeWVtmlQL4Ze7ZI8RwxJ9GibSFxszX20\nrlu3jo4dOxIXF8crr7xCjx49aNmyZY29vj8sURhjjMem/D2kZ+a6jxgy8/hp626qVJFo1ziuUtP5\n5OYNiDqKMtLh7N27l6lTp/K3v/2N2bNnM3ToUC68sLo5q4FjicIYUyuVlbv4aWsB6Z4FbUuy8thS\npYwUEyV0a9PI23RObZ9E8xooIx3ON998w4gRI1i7di1//OMfueSSSwL+ntWxRGGMqRUK9payzLOo\nbUlWLsuy8ymuUkZqWC/Gc6TQmNT2SaS0SaR+bHRQ45w6dSqTJ0+mXbt2fPTRR5x//vlBff+DsURh\njIk4qkpO3h7PXCR343ntQcpI7ZvEVWo6n9QsISBlJH9jFhF69OjBbbfdxsMPP0xCQoIjsVQl7gXS\n4cOmxxpjqiord7F6y25v0zk9K5ffdu+rtE2daKFLK08ZqUMSvdon0bxB4MtIh5Obm8v48eM56aST\nmDRpUsDeR0SWqGra0XyvHVEYY8LO7r2lLK04WsjMY/nGfPaUVi4jNapfZ3/T2bOorV6d4JaRDuet\nt97i1ltvJTc3N6BJ4lhZojDGhLSKMpLvbKS1vxVQtRhyfNN492mqHdyJ4UQHy0iHs2XLFsaOHcvb\nb79NamoqCxYsICUlxemwDskShTEmpJSWu1i9ebe36Zyemce2ggPLSN1aN/I2nVPbJ9E0oa5DER+5\nzZs389FHH/G3v/2NO++8k5iY0P4oDu3ojDERb9eeUpZm57HEMxvpx427DigjJcVVlJHcTedurRuF\nXBnpcDIzM3n33Xe57bbbSE1NZePGjSQlJTkdll8sURhjgkZVyc4tdpeQPMlh3bYDy0gnNI33GbHd\nmBObxQdtXEVNKy8v57nnnuO+++4jKiqKwYMH07Jly7BJEmCJwhgTQCVlLlZt3uVtOi/JzmN7lTJS\nbHSUd1FbRRmpSRiVkaqzZs0aRo4cyaJFi7jwwguZMWNG0Mdv1ARLFMaYGrOruJQl2bmeEdt5rMjJ\nZ2+pq9I2jeNjKzWdu4ZhGckfxcXF9OvXD5fLxcsvv8zQoUPD9qjIEoUx5qioKlk7iys1nX/eVnjA\ndic2iyetfWNSPYnh+KbhW0byx08//USnTp2Ii4tjzpw5pKSk0KJFC6fDOiaWKIwxfikpc7Fy8y5v\n03lJVj47CquUkWKiSGnTyN10bu9e1NY4PtahiINrz549TJkyhccee4yXXnqJoUOHhsT4jZpgicIY\nc1D5xSU+113I48ecfPaVVS4jNYmPrdR07tq6IXVjIq+MdDhffvklI0eO5Oeff2bkyJFceumlTodU\noyxRGGNQVX7dUeRzpbY81h+kjHRS8wRv0zmtQ2M6NImL6DKSPx588EGmTJnC8ccfzyeffMLAgQOd\nDqnGWaIwphbaV1bOyk27vE3npVl57CwqqbRN3ZgoUtokensLvdolkVRLykj+qBjil5aWxvjx45k6\ndSrx8fFOhxUQNhTQmFogt6jEOyxvSWYeKzbtoqRKGalpQqx3kmpqhyS6tmpEbEyUQxGHrh07djB+\n/Hg6duzIAw884HQ4frOhgMYYL1Vlw44ib9M5PSuPDduLDtju5BYJ3qZzWock2jW2MlJ1VJU333yT\nsWPHkpeXx+TJk50OKWgsURgT5vaWespInkVtS7PzyK1SRqpXx11Gcq9daEyvdkk0iqvjUMThZ/Pm\nzYwZM4a5c+eSlpbGJ598Qvfu3Z0OK2gsURgTZnYW7qt0QZ6MnF2UlFcuIzVrULdS0zn5uIZWRjoG\nW7du5bPPPuPRRx/ljjvuCPkhfjWtdv20xoQZVeWX7YX7R2Bk5bFhR+Uykgh0atHA23ROa9+Yto3r\nWxnpGG3YsIF58+Zxxx130KtXL7Kzs0lMTHQ6LEdYojAmhOwtLWdFzi5v03lJdh75xaWVtqlXJ4oe\nbRO9Tede7ZJoVN/KSDWlvLycp59+mokTJ1KnTh2GDBlCy5Yta22SAEsUxjhqR+E+z5GCu+m8ctMu\nSssrn4nYvEFd74K2tPZJJLdqSJ1oKyMFwqpVqxgxYgTff/89l1xyCS+88EJYDvGraZYojAkSl8td\nRkr3lpFyydxZXGkbETilZQNv0zm1fRJtkqyMFAzFxcWcffbZiAj//ve/GTJkiO13D0sUxgTI3tJy\nftyY7xma5/7atadyGSkuNtpTRkoitUNjerZLpGE9KyMF0+rVq+ncuTNxcXG8/vrrpKSk0KxZM6fD\nCimWKIypIdsL9nmnqKZn5bFq84FlpJYN61VqOnc+rgExVkZyRHFxMZMnT+aJJ55g9uzZDBs2jHPP\nPdfpsEKSJQpjjoLLpfy8rXD/auesPLKqlJGiBDof19C7oC21fRKtE62MFAq++OILbrrpJtavX8/N\nN9/MoEGDnA4ppFmiMMYPe0rKWb4x39t0XpqVx+69ZZW2iYuNpme7RG/TuWe7RBpYGSnkTJ48mYce\neogTTzyRzz77jAEDBjgdUsizRGHMQWzbvbdS03nV5t2UuSqXkY5rVM8zG8m9qO2UllZGCmUVQ/xO\nPfVU7rrrLh566CHi4uKcDissBHQooIhcCDwFRAOzVHValecbAa8C7XAnrcdU9V/VvaYNBTQ1zeVS\n1m0r8C5oS8/KZWPunkrb+JaRUju4jxhaJdZ3KGJzJLZv387tt99Op06datV8pqpCciigiEQDzwHn\nATnAYhGZp6qrfTa7FVitqpeJSDNgrYjMUdWSg7ykMTWiuKTMXUaqGLGdnUdBlTJSQt0YTxnJ3XTu\n0S6RhLp2AB5OVJXXXnuNcePGsXv3bh588EGnQwpbgfzNPxVYr6obAETkdeBywDdRKNBA3N29BCAX\nKKv6QsYci9927/WcieRuOq/avJvyKmWk1on1fa7UlsQpLRsSHWVN53CVk5PDLbfcwnvvvcdpp53G\nP//5T7p06eJ0WGErkImiNbDR534OcFqVbZ4F5gGbgQbAtarqqrINIjIKGAXQrl27gARrIkO5S1m7\ntYAl2XksyXQ3nnPyKpeRoqOErq0behe0pXVI4rhGVkaKJNu3b+fLL7/kiSeeYNy4cURH177Ls9Yk\np4+lLwCWA+cAJwIfi8hXqrrbdyNVnQnMBHePIuhRmpBVtM9dRqo4YlienU/BvoOXkdLaNyatQxI9\n2iYSb2WkiLN+/Xreffddxo8fT8+ePdm4cSMNGzZ0OqyIEMj/WzYBbX3ut/E85uuPwDR1d9TXi8iv\nwCnADwGMy4SxLbv2VGo6r9lScEAZqU1S/UpN55NbNLAyUgQrKyvjySefZNKkSdStW5frr7+eFi1a\nWJKoQYFMFIuBjiJyPO4EMQS4vso22cBA4CsRaQF0AjYEMCYTRspdyk9bd1casb0p/8AyUvc2jbxN\n57QOSbRoWM+hiE2wZWRkMGLECBYvXsygQYN4/vnnadGihdNhRZyAJQpVLRORscBHuE+PfVFVV4nI\naM/zLwBTgdkikgEIcK+q7ghUTCa0Fe4rY3l2vrfpvCw7n8IqZaQG9WLo1S7Jc8TgLiPFxVoZqTYq\nLi5mwIABREVF8frrr3PNNdfYqvcACeg6ikCwdRSRY3P+HvfAPE/Tec2W3VSpItG2cf1KTeeTmzcg\nyspItdrKlSvp0qULIsKnn35KSkoKTZs2dTqskBeS6yiM8VVW7uKnrQXey3cuycxl8669lbaJiRK6\ntW7oHoHhGZzX3MpIxqOoqIhJkybx5JNP8tJLLzFs2DAGDhzodFi1giUKExAFe0tZlp3vnYu0LDuP\nopLySts0rBdDL88IjNT2jenRNpH6sXYaoznQp59+yk033cSvv/7KmDFjuPzyy50OqVaxRGGOmaqy\nKX+Pt+mcnpXH2q0HlpHaN4mr1HQ+qVmClZHMYU2aNIm//OUvdOzYkYULF9KvXz+nQ6p1LFGYI1ZW\n7mLNlgLSPZNUl2TmsXV35TJSnWihe6tG3hHbvdon0byBlZGM/1wuF1FRUZx55pn86U9/YsqUKdSv\nbwsjnWDNbHNYuz1lpIqm8/KN+RRXKSM1ql+H1PZJ3mmqKW0TqVfHykjmyG3bto1x48bRqVMnm89U\ng6yZbWqMqpKTt8e7oC09M4+1vxVQ9e+JDk3iKjWdT7QykjlGqsqcOXO4/fbbKSws5KGHHnI6JONh\niaKWKy13sWbL7kqrnX/bva/SNnWiha6tG3mbzqntk2jWoK5DEZtItHHjRkaPHs38+fM544wzmDVr\nFsnJyU6HZTwsUdQyu/aUsjTbfSZSeqa7jLSntHIZKSmuoozkTgrd2zSyMpIJqJ07d/LNN9/w1FNP\nceutt9oQvxBjiSKCqSobc/dUajqv23ZgGemEpvE+I7Ybc2KzeFvhagJu3bp1zJs3j7vvvpsePXqw\nceNGGjRo4HRY5iAsUUSQ0nIXqzbvJj0z17uwbXtB5TJSbHQU3dpUlJHcX00SrIxkgqesrIzHH3+c\nyZMnU79+fYYNG0aLFi0sSYQwSxRhbFexu4xU0XT+MSefvaWVL+fhLiPtbzp3bW1lJOOcH3/8kRtv\nvJGlS5dyxRVX8Nxzz9kQvzBgiSJMqCrZucXeBW1LsnJZ91vhAdud0CzevXahfWNSOyRxQlMrI5nQ\nUFxczMCBA4mJieGtt97iqquucjok4ydLFCGqpMzFqs27Kq123lFYpYwUE0X31o1I7ZDkHZzXOD7W\noYiNObgVK1bQrVs34uLiePPNN0lJSaFx48ZOh2WOgCWKEJFfXMKSrDxvb+HHjfnsK6tcRmoSH1vp\nus5dWzeiboyVkUxoKiwsZOLEiTzzzDPMnj2b4cOHM2DAAKfDMkfBEoUDVJXMncWVms7rtx1YRjqp\neYK36ZzWoTEdmsRZGcmEhY8//phRo0aRmZnJ2LFjueKKK5wOyRwDSxRBsK+snJWbdrPE03Remp3H\njsKSStvUjYkipU2ip4yURK92SSRZGcmEoYkTJ/LXv/6VTp068dVXX9GnTx+nQzLHyBJFAOQVley/\n7kJWLj/m7KKkShmpaUKsd5JqaockurZqRGxMlEMRG3PsKob49enThwkTJvDAAw9Qr54NgowENhTw\nGKkqv+4o8i5oS8/K5ZftRQds17F5gndBW1r7JNpbGclEiK1btzJ27FiSk5NtPlMIC+hQQHF/mt0A\nnKCqD4lIO6Clqv5wNG8Y7txlpF3eM5GWZuWxs6hyGaleHXcZqaLp3KtdEolxVkYykUVVeemll7jz\nzjspLi7m9NNPdzokEyD+lJ6eB1zAOcBDQAHwX6B3AOMKGarKVz/v4JtfdrAkM48Vmw4sIzVrULdS\n0zn5uIZWRjIRLSsri1GjRrFgwQL69OnDrFmz6NSpk9NhmQDxJ1Gcpqq9RGQZgKrmiUit+fN44brt\n/OFfi733RaBTiwbepnNa+8a0bVzfykimVsnPz2fx4sU8++yz3HLLLURF2R9GkcyfRFEqItGAAohI\nM9xHGLXC4sxcAM4+uRl/OKsDvdol0ah+HYejMib41q5dy7x587jnnntISUkhOzubhIQEp8MyQeDP\nnwFPA/8DmovIw8DXwCMBjSqEZGzaDcB1p7ZlQKfmliRMrVNaWsojjzxCSkoK06ZNY9u2bQCWJGqR\nwx5RqOocEVkCDAQE+J2qrgl4ZCFAVVm5aRcAXVs3cjgaY4Jv2bJljBgxgmXLlnH11Vfz7LPP0rx5\nc6fDMkHmz1lPr6jqMOCngzwW0Tbl7yG3qISkuDq0TrSLupvapbi4mPPOO486derw3//+lyuvvNLp\nkIxD/OlRdPG94+lXpAYmnNBScTTRrU2iNatNrbFs2TJ69OhBXFwcb731FikpKSQlJTkdlnHQIXsU\nIjJBRAqA7iKyW0QKPPe3AXODFqGDMioSReuGDkdiTOAVFBQwduxYevXqxSuvvAJA//79LUmYQx9R\nqOojwCMi8oiqTghiTCGjopHdzfoTJsJ9+OGH3HzzzWzcuJHbb7/dykymEn+a2RNEJAnoCNTzefzL\nQAbmNFUlIycfsEa2iWwTJkxg2rRpdO7cmW+++YYzzjjD6ZBMiPGnmT0SuB1oAywHTge+xb1SO2Jt\nyt9DXnEpjeNjrZFtIlJ5eTnR0dH079+fmJgY7r//furWteunmwP5s47idtzjOrJUdQDQE8gPaFQh\nwPe0WGtkm0iyZcsWrrzySqZMmQLABRdcwNSpUy1JmEPyJ1HsVdW9ACJSV1V/AiJ+qMuKHGtkm8ii\nqvzrX/8iOTmZDz74wJrUxm/+nB6bIyKJwDvAxyKSB2QFNizn7T/jKdHhSIw5dpmZmdx000188skn\n9O3bl1mzZnHyySc7HZYJE/40syuuYThFRD4HGgEfBjQqh/muyO7WxhrZJvzt2rWLpUuX8vzzz3Pz\nzTfbED9zRKr9bRGRaBHxrshW1YWqOk9VS6r7Pp/vv1BE1orIehH58yG26S8iy0VklYgsPLLwA8O3\nkd2qkV2hy4Sn1atXM23aNADvED+b9GqORrW/MapaDqz1XKzoiHhWcD8HXAQkA9eJSHKVbRJxX+9i\nkKp2AQYf6fsEQkaONbJN+CopKeEvf/kLPXv25LHHHvMO8YuPj3c4MhOu/OlRJAGrROQHwHuNT1Ud\ndJjvOxVYr6obAETkdeByYLXPNtcDb6tqtuc1tx1B7AFT0Z/obusnTJhJT09nxIgRrFixgiFDhvDU\nU0/ZED9zzPxJFJOO8rVbAxt97ucAp1XZ5mSgjoh8ATQAnlLVl6u+kIiMAkYBtGt3xAc3RyzDJsaa\nMFRUVMQFF1xAvXr1mDt3LoMGHe5vOWP8408zO5B9gxjcAwYHAvWBb0XkO1VdVyWGmcBMgLS0NA1g\nPNbINmFn6dKl9OjRg/j4eP73v//RvXt3EhPtbD1TcwLZ1doEtPW538bzmK8c4CNVLVLVHcCXQEoA\nYzqsnDxrZJvwsHv3bsaMGUNqaiqvvvoqAP369bMkYWpcIBPFYqCjiBzvucb2EGBelW3mAn1EJEZE\n4nCXphy9KJL3aMIa2SaEzZ8/ny5dujBjxgzuvPNOrrrqKqdDMhHMr0QhIvVF5IhWY6tqGTAW+Aj3\nh/9/VHWViIwWkdGebdbgXpOxAvgBmKWqK4/kfWpahk+iMCYU3XvvvVxyySU0bNiQRYsW8fjjj9sZ\nTSag/BkKeBnwGBALHC8iPYCH/DjrCVWdD8yv8tgLVe4/Cjx6JEEHkjWyTShSVVwuF9HR0QwcOJB6\n9epx33332XwmExT+HFFMwX2qaz6Aqi4Hjg9gTI5R1f2nxloj24SITZs28bvf/Y7JkycDcP755/Pg\ngw9akjBB40+iKFXVXVUeC+iZR07JydtDfnEpTeJjOc4a2cZhqso//vEPkpOTWbBgAU2bNnU6JFNL\n+bOOYpWIXA9Ei0hHYBywKLBhOcNGi5tQ8euvvzJixAg+//xz+vfvzz/+8Q9OOukkp8MytZQ/RxS3\nAV2AfcC/gV3AHYEMyikrrJFtQkRhYSErVqxgxowZfPrpp5YkjKP8OaI4RVUnAhMDHYzTbKGdcdLK\nlSuZN28e9913H926dSM7O5u4uDinwzLGryOKx0VkjYhMFZGuAY/IIb6NbDuiMMFUUlLCgw8+SK9e\nvfj73//uHeJnScKEisMmCs/lTwcA24EZIpIhIvcHPLIgs0a2ccLixYtJTU1lypQpDB48mNWrV9sQ\nPxNy/Fpwp6pbVfVpYDSwHHggoFE5IMMa2SbIioqKuPDCC8nLy2PevHnMmTOHZs2aOR2WMQfwZ8Fd\nZ+Ba4CpgJ/AGcFeA4wo6Wz9hgiU9PZ1evXoRHx/P3Llz6datG40a2e+dCV3+HFG8iHux3QWq2l9V\np4fKdSNq0kpbkW0CbNeuXdx888307t3bO8SvT58+liRMyPNnzPgZwQjESarKihxrZJvAeffddxk9\nejRbt27l7rvv5uqrr3Y6JGP8dshEISL/UdVrRCSDyiuxBVBV7R7w6IIkJ28Pu/aU0jTBGtmm5t1z\nzz089thjdOvWjXfeeYfevXs7HZIxR6S6I4rbPf9eGoxAnGSNbFPTVJXy8nJiYmI4//zzadiwIffe\ney+xsbFOh2bMETtkj0JVt3hujlHVLN8vYExwwgsOWz9halJOTg6DBg3yDvE777zzmDRpkiUJE7b8\naWafd5DHLqrpQJyUkWONbHPsXC4XM2bMIDk5mc8++4yWLVs6HZIxNaK6HsUtuI8cThCRFT5PNQC+\nCXRgwWKjxU1N2LBhAzfeeCMLFy5k4MCBzJw5kxNOOMHpsIypEdX1KP4NfAA8AvzZ5/ECVc0NaFRB\n5NvIbtnQGtnm6BQVFbF69WpmzZrFjTfeaL0uE1GqSxSqqpkicmvVJ0SkcaQkixU51sg2RycjI4O5\nc+dy//33061bN7Kysqhfv77TYRlT46rrUfzb8+8SIN3z7xKf+xHBGtnmSO3bt48HHniAXr168fTT\nT3uH+FmSMJHqkEcUqnqp59+IvOxphZWWKMwR+O677xgxYgSrV69m2LBh/P3vf6dJkyZOh2VMQPkz\n6+ksYLmqFonIUKAX8KSqZgc8ugCrNFrcGtnmMIqKirjkkkuIj49n/vz5XHRRRJ38Z8wh+XN67HSg\nWERScA8D/AV4JaBRBcnGXGtkm8P7/vvvcblcxMfH8+6777Jq1SpLEqZW8SdRlKmqApcDz6rqc7hP\nkQ17vv0Ja2SbqvLz8xk5ciSnn366d4jfmWeeSYMGEfHrb4zf/LkUaoGITACGAX1FJAqoE9iwgsMa\n2eZQ3nnnHcaMGcO2bdu49957GTx4sNMhGeMYf44orgX2ATeq6lagDfBoQKMKkoxN+YCtyDaV3Xnn\nnVxxxRU0b96c77//nmnTptkZTaZW82fM+FYRmQP0FpFLgR9U9eXAhxZYqsrKTbsBa2SbykP8Lr74\nYpo0acKf/vQn6tSJiINnY47JYY8oROQa4AdgMHAN8L2IhP0w/f2N7LrWyK7lsrOzueSSS7xD/M49\n91wmTpxoScIYD39KTxOB3qr6e1UdDpwKTApsWIG3vz/R0BrZtZTL5eL555+nS5cuLFy4kFatWjkd\nkjEhyZ9mdlSVS5/uxL8EE9JWePoT1siundavX8+NN97IV199xXnnncfMmTPp0KGD02EZE5L8SRQf\nishHwGue+9cC8wMXUnDYNbJrt71797Ju3Tr+9a9/8fvf/96OKo2phj/N7HtE5Eqgj+ehmar6v8CG\nFVi+jezubRIdjsYEy/Lly5k7dy6TJ0+ma9euZGZmUq+e9aeMORx/S0iLgIXA58C3gQsnOHwb2S0a\n1nU6HBNge/fuZeLEiaSlpTF9+nTvED9LEsb4x5+znkbiPuvpCuBq4DsRuTHQgQXS/v6ENbIj3aJF\ni+jZsyd//etfGTp0KKtXr6Z58+ZOh2VMWPGnR3EP0FNVdwKISBPcRxgvBjKwQNo/CNDKTpGsqKiI\nyy67jISEBD788EMuuOACp0MyJiz5kyh2AgU+9ws8j4UtGy0e2b799ltOO+004uPjee+99+jatavN\nZzLmGPjTo1iPe5HdFBGZDHwHrBORO0Xkzuq+UUQuFJG1IrJeRP5czXa9RaQsGAv5VJWMHEsUkSgv\nL48bb7yRM888k1decQ84PuOMMyxJGHOM/Dmi+MXzVWGu599q/+8TkWjgOeA8IAdYLCLzVHX1Qbb7\nG7DA36Dv9unzAAAWeElEQVSPRXZuMbv3llkjO8K8/fbb3HrrrWzfvp0JEyZw7bXXOh2SMRHDn9Nj\nHzzK1z4VWK+qGwBE5HXco8pXV9nuNuC/QO+jfJ8jUtGf6N7GRotHivHjx/Pkk0/So0cP5s+fT8+e\nPZ0OyZiI4s8RxdFqDWz0uZ8DnOa7gYi0xn021QCqSRQiMgoYBdCuXbtjCirDFtpFBN8hfpdeeinN\nmzfn7rvvtvlMxgSA06M4ngTuVVVXdRup6kxVTVPVtGbNmh3TG1p/IvxlZmZy4YUXMmmSe+TYwIED\nmTBhgiUJYwIkkIliE9DW534bz2O+0oDXRSQT9xqN50Xkd4EKyL0ie3/pyYQXl8vFM888Q9euXVm0\naBHt27d3OiRjagV/FtydLCKfishKz/3uInK/H6+9GOgoIseLSCwwBJjnu4GqHq+qHVS1A/AWMEZV\n3znin8JPFY3sZg3q0sJGi4eVn3/+mX79+jFu3Dj69u3LypUrGT16tNNhGVMr+HNE8Q9gAlAKoKor\ncH/oV0tVy4CxwEfAGuA/qrpKREaLiCP/h6+wslPYKikp4ZdffuHll19m/vz5djRhTBD508yOU9Uf\nqpwhVObPi6vqfKpMmlXVFw6x7R/8ec1jYRNjw8uyZcuYO3cuU6ZMoUuXLmRmZlK3rp3SbEyw+XNE\nsUNETgQUwLMobktAowoQ76mxlihC2t69e5kwYQK9e/dmxowZbN++HcCShDEO8SdR3ArMAE4RkU3A\nHcAtAY0qAFTVZ8aTJYpQ9fXXX5OSksK0adMYPnw4q1ev5ljPdDPGHBt/FtxtAM4VkXjcV7srONz3\nhKKsncUUWCM7pBUWFnL55ZfTsGFDFixYwHnnned0SMYY/EgUIvJAlfsAqOpDAYopIDJsEGDI+vrr\nrznzzDNJSEjg/fffp2vXriQkJDgdljHGw5/SU5HPVzlwEdAhgDEFhE2MDT07d+5k+PDh9O3b1zvE\n7/TTT7ckYUyI8af09LjvfRF5DPcpr2HFjihCh6ry1ltvMXbsWHJzc5k0aRJDhhz2jGtjjEOOZtZT\nHO5V1mHDGtmhZfz48Tz11FOkpqayYMECUlJSnA7JGFMNf3oUGXhOjQWigWZAWPUnKhrZza2R7RhV\npaysjDp16jBo0CBatWrFnXfeSUxMIOdSGmNqgj//l17qc7sM+M2z6jpsWNnJWb/++iujRo0iNTWV\nadOmcc4553DOOec4HZYxxk/VNrM9FxX6SFWzPF+bwi1JgI0Wd0p5eTlPPfUUXbt25fvvv+eEE05w\nOiRjzFGo9ohCVcs9lzJtp6rZwQqqptlo8eBbt24df/jDH/j222+56KKLmDFjBm3btj38NxpjQo4/\npackYJWI/ID7FFkAVHVQwKKqQarKys3WyA62srIysrKyePXVV7n++uvtaoLGhDF/EsWkgEcRQNbI\nDp709HTmzp3L1KlTSU5OZsOGDTafyZgI4M+Cu4tVdaHvF3BxoAOrKSuskR1we/bs4U9/+hOnnXYa\nL774og3xMybC+JMoDjZw56KaDiRQbLR4YC1cuJDu3bvz6KOPMmLECFatWmVD/IyJMIcsPYnILcAY\n4AQRWeHzVAPgm0AHVlMqGtl26dOaV1hYyJVXXkliYiKffvqpnfJqTISqrkfxb+AD4BHgzz6PF6hq\nbkCjqiEul9qMpwD46quvOOuss0hISOCDDz6gS5cuxMfHOx2WMSZADll6UtVdqpqpqtf5rKPICpck\nAZCVW0zBPncju7k1so/Zjh07GDp0KP369fMO8Tv11FMtSRgT4SJ6foL3inZWdjomqsp//vMfbrvt\nNvLy8pg8ebIN8TOmFonoRGGN7Jpx++2388wzz9C7d28+/fRTunXr5nRIxpggiuhEsSInH7D+xNFQ\nVUpLS4mNjeWKK66gffv23HHHHURHRzsdmjEmyPw5PTYsuVzKqk27AUsUR+qXX35h4MCB3H///QAM\nGDCAu+66y5KEMbVUxCaKikZ2i4bWyPZXeXk5TzzxBN26dWPJkiV06tTJ6ZCMMSEgYktPNlr8yPz0\n00/8/ve/54cffuCyyy5j+vTptG7d2umwjDEhIHIThac/YY1s/7hcLjZv3sxrr73Gtddea0P8jDFe\nkZso7IjisH744Qfmzp3Lww8/THJyMr/88guxsbFOh2WMCTER2aOwRnb1iouLufvuuznjjDN46aWX\nvEP8LEkYYw4mIhNF5s4ia2Qfwueff063bt14/PHHuemmm2yInzHmsCKy9GRlp4MrLCxk8ODBJCYm\n8vnnn9O/f3+nQzLGhIGIPKLYPwgw0eFIQsMXX3yBy+XyDvFbsWKFJQljjN8iMlF4jyjaNHQ4Emdt\n376d6667jgEDBvDqq68C0Lt3b+Li4hyOzBgTTiKu9OQeLe5uZNfWU2NVlddee41x48ZRUFDA1KlT\nbYifMeaoRVyiyNxZRGFFI7tB7Wxk33bbbTz33HOcfvrp/POf/yQ5OdnpkIwxYSziEkVGLe1PuFwu\nysrKiI2N5eqrr+akk07itttus/lMxphjFtAehYhcKCJrRWS9iPz5IM/fICIrRCRDRBaJSMqxvmfF\npU9r0xlPP//8M+eccw4TJ04EoH///jbp1RhTYwKWKEQkGngOuAhIBq4Tkao1kF+Bs1W1GzAVmHms\n71ubGtllZWU89thjdO/eneXLl9O5c2enQzLGRKBAlp5OBdar6gYAEXkduBxYXbGBqi7y2f47oM2x\nvKHLpazaXDsa2WvWrGH48OGkp6dz+eWX8/zzz9OqVSunwzLGRKBAJorWwEaf+znAadVsPwL44GBP\niMgoYBRAu3btDvkCFY3slg3r1YpG9m+//cYbb7zB4MGDbYifMSZgQmIdhYgMwJ0o7j3Y86o6U1XT\nVDWtunETGRF+6dPvvvuOCRMmANC5c2d++eUXrrnmGksSxpiACmSi2AS09bnfxvNYJSLSHZgFXK6q\nO4/lDSO1kV1UVMT48eM588wzmTNnjneIX506dRyOzBhTGwQyUSwGOorI8SISCwwB5vluICLtgLeB\nYaq67ljfsOKIonubyEkUn3zyCV27duXJJ59kzJgxNsTPGBN0AetRqGqZiIwFPgKigRdVdZWIjPY8\n/wLwANAEeN5TPilT1bSjeb9IbGQXFhYyZMgQGjduzJdffknfvn2dDskYUwsFdMGdqs4H5ld57AWf\n2yOBkTXxXr/6NLKbNahbEy/pmM8++4yzzz6bhIQEPvroI5KTk6lfv77TYRljaqmQaGbXhJUR0Mj+\n7bffuOaaaxg4cKB3iF9qaqolCWOMoyImUVQ0ssOxP6GqvPLKKyQnJ3svTXr99dc7HZYxxgARNOtp\nRRhfrOjWW29l+vTpnHHGGfzzn/+0FdbGmJASEYnC5VJWh1kj2+VyUVpaSt26dbn22mvp3LkzY8aM\nsflMxpiQExGlp3BrZK9du5azzz7bO8Tv7LPPtkmvxpiQFRGJwnvp0xDvT5SWljJt2jRSUlJYuXIl\n3bp1czokY4w5rIgoPa0IgxXZq1atYtiwYSxbtowrr7yS5557jpYtWzodljHGHFZEJIqMMGhkR0dH\nk5uby1tvvcVVV13ldDjGGOO3sC89uVzKqhBdQ7Fo0SLuvdc95/CUU05h/fr1liSMMWEn7BPFhh1F\nFJWUc1yj0GlkFxYWMm7cOPr06cMbb7zBjh07AIiJiYgDOGNMLRP2iSLUVmQvWLCArl278uyzzzJ2\n7FhWrlxJ06ZNnQ7LGGOOWtj/iRtK/YnCwkJuuOEGmjRpwldffcVZZ53ldEjGGHPMwv6IIiMETo39\n+OOPKS8vJyEhgQULFrB8+XJLEsaYiBHWicK3ke3EEcWWLVu46qqrOP/885kzZw4APXv2pF69yL8M\nqzGm9gjrROHbyG6aELxGtqoye/ZskpOTef/995k2bZoN8TPGRKyw7lE41ci+5ZZbmDFjBn369GHW\nrFl06tQpqO9vjDHBFNaJomJFdvcgJArfIX7XX3893bt3Z/To0URFhfVBmTHGHFZYf8p5jygC3Mhe\ns2YNffv25b777gOgX79+jBkzxpKEMaZWCNtPOvc1sgPbyC4tLeWvf/0rPXr04KeffqJnz54BeR9j\njAllYVt6qmhktwpQI3vVqlUMHTqU5cuXM3jwYJ555hlatGhR4+9jjDGhLmwTRcamfCBwjeyYmBh2\n7drF22+/zRVXXBGQ9zDGmHAQtqWnjBz3Fe1qsuz01VdfcffddwPQqVMn1q1bZ0nCGFPrhW2iqMlG\ndkFBAbfeeiv9+vXj7bfftiF+xhjjIywTRXkNNrI/+OADunTpwvTp07njjjvIyMiwIX7GGOMjLP9k\n/nVHYY00sgsKChg+fDjNmzdn0aJFnH766TUYpTHGRIawPKLIOIYV2arKhx9+SHl5OQ0aNOCTTz5h\n6dKlliSMMeYQwjNRHGUje8uWLVx55ZVcdNFF3iF+KSkp1K0bGhc8MsaYUBSeicJzaqy/o8VVlRdf\nfJHOnTvz4Ycf8n//9382xM8YY/wUlj2KVZuP7Ihi9OjRzJw5k379+jFr1iw6duwYyPCMMSaihF2i\n2FfmotjTyG5STSO7vLyc0tJS6tWrx9ChQ+nZsyejRo2y+UzGGHOEwu5Tc09JGVB92WnVqlWcddZZ\n3iF+ffv2tUmvxhhzlMLuk7O4tBw4eNmppKSEqVOn0rNnT9avX0/v3r2DHZ4xxkScsCs97S0pJ5YD\nT43NyMjghhtuICMjgyFDhvD000/TrFkzZ4I0xpgIEnaJYk+pi4YceEQRGxtLcXExc+fOZdCgQc4E\nZ4wxESjsSk8uVVon1qdJQl0WLlzIXXfdBbiH+K1du9aShDHG1LCAJgoRuVBE1orIehH580GeFxF5\n2vP8ChHp5c/rntw4iltuuYX+/fvzzjvveIf4RUdH1/BPYIwxRlQ1MC8sEg2sA84DcoDFwHWqutpn\nm4uB24CLgdOAp1T1tOpet07jVpoQo+zeuY077riDqVOnEhcXF5CfwRhjIoWILFHVtKP53kD2KE4F\n1qvqBgAReR24HFjts83lwMvqzlbfiUiiiBynqlsO9aJl+b+ReFJHPnz3HU47rdqcYowxpgYEMlG0\nBjb63M/BfdRwuG1aA5UShYiMAkZ57u7L/HntShviB0BTYIfTQYQI2xf72b7Yz/bFfp2O9hvD4qwn\nVZ0JzAQQkfSjPXyKNLYv9rN9sZ/ti/1sX+wnIulH+72BbGZvAtr63G/jeexItzHGGOOgQCaKxUBH\nETleRGKBIcC8KtvMA4Z7zn46HdhVXX/CGGNM8AWs9KSqZSIyFvgIiAZeVNVVIjLa8/wLwHzcZzyt\nB4qBP/rx0jMDFHI4sn2xn+2L/Wxf7Gf7Yr+j3hcBOz3WGGNMZAi7ldnGGGOCyxKFMcaYaoVsogjU\n+I9w5Me+uMGzDzJEZJGIpDgRZzAcbl/4bNdbRMpE5OpgxhdM/uwLEekvIstFZJWILAx2jMHix/8j\njUTkXRH50bMv/OmHhh0ReVFEtonIykM8f3Sfm6oacl+4m9+/ACcAscCPQHKVbS4GPgAEOB343um4\nHdwXZwJJntsX1eZ94bPdZ7hPlrja6bgd/L1IxD0JoZ3nfnOn43ZwX9wH/M1zuxmQC8Q6HXsA9kU/\noBew8hDPH9XnZqgeUXjHf6hqCVAx/sOXd/yHqn4HJIrIccEONAgOuy9UdZGq5nnufod7PUok8uf3\nAtzzw/4LbAtmcEHmz764HnhbVbMBVDVS94c/+0KBBiIiQALuRFEW3DADT1W/xP2zHcpRfW6GaqI4\n1GiPI90mEhzpzzkC918Mkeiw+0JEWgNXANODGJcT/Pm9OBlIEpEvRGSJiAwPWnTB5c++eBboDGwG\nMoDbVdUVnPBCylF9bobFCA/jHxEZgDtR9HE6Fgc9Cdyrqi73H4+1WgyQCgwE6gPfish3qrrO2bAc\ncQGwHDgHOBH4WES+UtXdzoYVHkI1Udj4j/38+jlFpDswC7hIVXcGKbZg82dfpAGve5JEU+BiESlT\n1XeCE2LQ+LMvcoCdqloEFInIl0AK7vH/kcSfffFHYJq6C/XrReRX4BTgh+CEGDKO6nMzVEtPNv5j\nv8PuCxFpB7wNDIvwvxYPuy9U9XhV7aCqHYC3gDERmCTAv/9H5gJ9RCRGROJwT29eE+Q4g8GffZGN\n+8gKEWmBe5LqhqBGGRqO6nMzJI8oNHDjP8KOn/viAaAJ8LznL+kyjcCJmX7ui1rBn32hqmtE5ENg\nBeACZqnqQU+bDGd+/l5MBWaLSAbuM37uVdWIGz8uIq8B/YGmIpIDTAbqwLF9btoID2OMMdUK1dKT\nMcaYEGGJwhhjTLUsURhjjKmWJQpjjDHVskRhjDGmWpYoTEgTkXEiskZE5lSzTX8ReS+YcR2KiAyq\nmF4qIr8TkWSf5x4SkXODGEt/ETkzWO9nIldIrqMwxscY4FxVzXE6EH+o6jz2L/b6HfAe7gmuqOoD\nNf1+IhKjqocabtcfKAQW1fT7mtrFjihMyBKRF3CPjv5ARMaLyKki8q2ILPNcd6PTQb7nbM/1F5Z7\ntmvgefweEVnsmcH/4CHer1BE/u65XsGnItLM83gPEfnO873/E5Ekz+PjRGS15/HXPY/9QUSe9fwl\nPwh41BPLiSIyW0SuFve1E970eV/vEZGInO/5GZeKyJsiknCQOL8QkSdFJB24XUQuE5HvPT/vJyLS\nQkQ6AKOB8Z737ysizUTkv579sFhEzjqG/zymNnF6frp92Vd1X0Am0NRzuyEQ47l9LvBfz+3+wHue\n2+8CZ3luJ+A+aj4f94XlBfcfR+8B/Q7yXgrc4Ln9APCs5/YK4GzP7YeAJz23NwN1PbcTPf/+wef7\nZuNzPYyK+56YsoF4z+PTgaG4Z1N96fP4vcADB4nzC+B5n/tJ7F88OxJ43HN7CnC3z3b/Bvp4brcD\n1jj939e+wuPLSk8mnDQCXhKRjrg/1OscZJtvgCc8PY23VTVHRM7HnSyWebZJADri/lD25QLe8Nx+\nFXhbRBrhTgIVV4d7Cag4GlgBzBGRdwC/50mpe+TEh8BlIvIWcAnwJ+BsIBn4xjOKJRb49hAv84bP\n7TbAG+K+rkAs8OshvudcIFn2T9VtKCIJqlrob+ymdrJEYcLJVOBzVb3CU1r5ouoGqjpNRN7HPc/m\nGxG5APeRxCOqOuMI3+9w820uwX1FscuAiSLS7Qhe+3VgLO6LzKSraoG4P8E/VtXr/Pj+Ip/bzwBP\nqOo8EemP+0jiYKKA01V17xHEaYz1KExYacT+kch/ONgGInKiqmao6t9wTxU9BfewuBsr6v0i0lpE\nmh/k26Nwl4bAfXW4r1V1F5AnIn09jw8DFopIFNBWVT/HXSJqhPtIxVcB0OAQP8tC3JesvAl30gD3\n1QnPEpGTPHHGi8jJh/h+X7775ffVvP8C3Ff/w/P6Pfx4bWMsUZiw8n/AIyKyjEMfDd8hIitFZAVQ\nCnygqgtw1+e/9UwPfYuDf4AXAaeK+8L05+DuR4D7w/dRz2v28DweDbzqeb1lwNOqml/l9V4H7vE0\nmU/0fUJVy3H3Si7y/IuqbsedAF/zvNe3uBPd4UwB3hSRJYDvRNR3gSsqmtnAOCDN03xfjbvZbcxh\n2fRYYzxEpFBVDzjLyJjazo4ojDHGVMuOKIwxxlTLjiiMMcZUyxKFMcaYalmiMMYYUy1LFMYYY6pl\nicIYY0y1/h8fMbf5X3ND4QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21ec6910c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, prediction)\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, label = None):\n",
    "    plt.plot(fpr, tpr, linewidth= 2, label = label)\n",
    "    plt.plot([0,1], [0,1], 'k--')\n",
    "    plt.axis([0,1,0,1])\n",
    "    plt.xlabel('false positive rate')\n",
    "    plt.ylabel('true positive rate')\n",
    "plot_roc_curve(fpr, tpr, thresholds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79428446970103606"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sk.metrics.con"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "forest = RandomForestClassifier(random_state = 42)\n",
    "from sklearn.cross_validation import cross_val_predict, cross_val_score\n",
    "y_proba_forest = cross_val_predict(forest, x_train, y_train, cv = 3)\n",
    "y_scores_forest = y_proba_forest[:,1]\n",
    "fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train, y_scores_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[63425,  5543],\n",
       "       [ 9908, 16881]])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cross_val_score(forest, x_train, y_train, cv = 3, scoring = 'accuracy')\n",
    "y_train_pred = cross_val_predict(forest, x_train, y_train, cv =3)\n",
    "conf_mx = confusion_matrix(y_train, y_train_pred)\n",
    "conf_mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAECCAYAAADesWqHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABZVJREFUeJzt2zGPVHUUxuFzYGNNwVZgWApiQr3xM2BlK7UJlR+AL2JD\nQew0lhYmtjYWLJ1GTIiJERvX0NEYkmMhBVYzu86du8v7PN1MJn/e5O5v7wy72zNTQJYraw8A9k/4\nEEj4EEj4EEj4EEj4EEj4Z9Dd97r7l+5+3t0P197D9rr7cXf/2d0/rr3lIhD+lrr7alV9XlUfVdXd\nqrrf3XfXXcUZfFFV99YecVEIf3sfVtXzmfl1Zv6uqq+q6uOVN7Glmfm+ql6uveOiEP72blTV7289\nfvHmObh0hA+BhL+9P6rq/bce33zzHFw6wt/ek6q60923u/u9qvqkqr5ZeROci/C3NDOvq+qzqvqu\nqn6uqq9n5qd1V7Gt7v6yqn6oqg+6+0V3f7r2pjW1P8uFPO74EEj4EEj4EEj4EEj4EEj4Z9TdD9be\nwPm5fv8S/tn5wrncXL8SPkRa5Bd4rl+/PkdHRzs/9yI4PT2tw8PDtWcs6unTp2tP4H+Ymd70moMl\n/uGjo6M6OTlZ4mj2oHvj1w2XnLf6EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4\nEEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4\nEEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EEj4EGir\n8Lv7Xnf/0t3Pu/vh0qOAZW0Mv7uvVtXnVfVRVd2tqvvdfXfpYcBytrnjf1hVz2fm15n5u6q+qqqP\nl50FLGmb8G9U1e9vPX7x5jngktrZf+5194PuPunuk9PT010dCyxgm/D/qKr333p8881z/zEzj2bm\neGaODw8Pd7UPWMA24T+pqjvdfbu736uqT6rqm2VnAUs62PSCmXnd3Z9V1XdVdbWqHs/MT4svAxaz\nMfyqqpn5tqq+XXgLsCd+cw8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8C\nCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8C\nCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8C9czs/NCD\ng4O5du3azs9lP27durX2BM7p2bNn9erVq970Ond8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8\nCCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8\nCCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8CCR8\nCCR8CCR8CCR8CCR8CLQx/O5+3N1/dveP+xgELG+bO/4XVXVv4R3AHm0Mf2a+r6qXe9gC7InP+BDo\nYFcHdfeDqnpQVXXliu8ncJHtrNCZeTQzxzNz3N27OhZYgFszBNrmx3lfVtUPVfVBd7/o7k+XnwUs\naeNn/Jm5v48hwP54qw+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+B\nhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+B\nhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BhA+BemZ2f2j3aVX9\ntvODL4brVfXX2iM4t3f9+t2amcNNL1ok/HdZd5/MzPHaOzgf1+9f3upDIOFDIOGf3aO1B/C/uH7l\nMz5EcseHQMKHQMKHQMKHQMKHQP8Ay6GwDQeSjUEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21ec696a780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(conf_mx, cmap = plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoosting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.849065864637 0.85021695202\n",
      "0.850308593628 0.850545904541\n",
      "0.851248472697 0.849887999499\n",
      "0.852574746494 0.850295274049\n",
      "0.855853880134 0.849527718166\n",
      "0.857744081373 0.848948135152\n",
      "0.860271311758 0.848572189414\n",
      "0.86316405067 0.848023935212\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "for i in range(2,10):\n",
    "    gbrt = GradientBoostingClassifier(random_state = 0, max_depth = i)\n",
    "    gbrt.fit(x_train, y_train)\n",
    "    print(gbrt.score(x_train, y_train),gbrt.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network with scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(solver = 'lbfgs', activation = 'relu', random_state = 0).fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84854370959825387"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.84725920820409995, 0.8493710741083037)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(solver = 'lbfgs', activation = 'logistic', random_state = 0, hidden_layer_sizes = [10]).fit(x_train, y_train)\n",
    "mlp.score(x_train, y_train), mlp.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.84738452541328568, 0.84940240291984526)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(solver = 'lbfgs', max_iter = 1000, alpha = 1, activation = 'logistic', random_state = 0, hidden_layer_sizes = [10]).fit(x_train, y_train)\n",
    "mlp.score(x_train, y_train), mlp.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.84050252200883491, 0.84214978304798005)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precetrons\n",
    "from sklearn.linear_model import Perceptron\n",
    "per_clf = Perceptron(random_state = 42)\n",
    "per_clf.fit(x_train, y_train)\n",
    "y_pred = per_clf.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "test_score = accuracy_score(y_pred, y_test)\n",
    "per_clf.score(x_train, y_train),test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorlfow higher level API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\INVENTAR\\AppData\\Local\\Temp\\tmp5tlx89ug\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000021EC8840B38>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'C:\\\\Users\\\\INVENTAR\\\\AppData\\\\Local\\\\Temp\\\\tmp5tlx89ug'}\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "WARNING:tensorflow:From C:\\Users\\INVENTAR\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\INVENTAR\\AppData\\Local\\Temp\\tmp5tlx89ug\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.680682, step = 1\n",
      "INFO:tensorflow:global_step/sec: 206.137\n",
      "INFO:tensorflow:loss = 0.407919, step = 101 (0.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.327\n",
      "INFO:tensorflow:loss = 0.334438, step = 201 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.416\n",
      "INFO:tensorflow:loss = 0.271743, step = 301 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.011\n",
      "INFO:tensorflow:loss = 0.361544, step = 401 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.381\n",
      "INFO:tensorflow:loss = 0.401049, step = 501 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.408\n",
      "INFO:tensorflow:loss = 0.326332, step = 601 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.136\n",
      "INFO:tensorflow:loss = 0.341803, step = 701 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.138\n",
      "INFO:tensorflow:loss = 0.355674, step = 801 (0.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.637\n",
      "INFO:tensorflow:loss = 0.351962, step = 901 (0.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.188\n",
      "INFO:tensorflow:loss = 0.363271, step = 1001 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.582\n",
      "INFO:tensorflow:loss = 0.367145, step = 1101 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.174\n",
      "INFO:tensorflow:loss = 0.364283, step = 1201 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.487\n",
      "INFO:tensorflow:loss = 0.445843, step = 1301 (0.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.455\n",
      "INFO:tensorflow:loss = 0.316225, step = 1401 (0.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.826\n",
      "INFO:tensorflow:loss = 0.38922, step = 1501 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.771\n",
      "INFO:tensorflow:loss = 0.344475, step = 1601 (0.527 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.541\n",
      "INFO:tensorflow:loss = 0.295004, step = 1701 (0.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.614\n",
      "INFO:tensorflow:loss = 0.401626, step = 1801 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.495\n",
      "INFO:tensorflow:loss = 0.281009, step = 1901 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.187\n",
      "INFO:tensorflow:loss = 0.263319, step = 2001 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.310772, step = 2101 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.495\n",
      "INFO:tensorflow:loss = 0.353159, step = 2201 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.141\n",
      "INFO:tensorflow:loss = 0.289763, step = 2301 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.741\n",
      "INFO:tensorflow:loss = 0.367555, step = 2401 (0.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.356\n",
      "INFO:tensorflow:loss = 0.447073, step = 2501 (0.515 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.164\n",
      "INFO:tensorflow:loss = 0.409175, step = 2601 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.783\n",
      "INFO:tensorflow:loss = 0.370954, step = 2701 (0.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.303\n",
      "INFO:tensorflow:loss = 0.338782, step = 2801 (0.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.049\n",
      "INFO:tensorflow:loss = 0.473819, step = 2901 (0.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.624\n",
      "INFO:tensorflow:loss = 0.316661, step = 3001 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.522\n",
      "INFO:tensorflow:loss = 0.344282, step = 3101 (0.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.281\n",
      "INFO:tensorflow:loss = 0.35505, step = 3201 (0.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.772\n",
      "INFO:tensorflow:loss = 0.293067, step = 3301 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.371\n",
      "INFO:tensorflow:loss = 0.447342, step = 3401 (0.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.365\n",
      "INFO:tensorflow:loss = 0.343572, step = 3501 (0.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.669\n",
      "INFO:tensorflow:loss = 0.295509, step = 3601 (0.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 190.948\n",
      "INFO:tensorflow:loss = 0.327507, step = 3701 (0.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.853\n",
      "INFO:tensorflow:loss = 0.293329, step = 3801 (0.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.454\n",
      "INFO:tensorflow:loss = 0.405681, step = 3901 (0.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.448\n",
      "INFO:tensorflow:loss = 0.397802, step = 4001 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.607\n",
      "INFO:tensorflow:loss = 0.302636, step = 4101 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.975\n",
      "INFO:tensorflow:loss = 0.253013, step = 4201 (0.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.967\n",
      "INFO:tensorflow:loss = 0.375581, step = 4301 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.218\n",
      "INFO:tensorflow:loss = 0.304067, step = 4401 (0.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.25\n",
      "INFO:tensorflow:loss = 0.267473, step = 4501 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.677\n",
      "INFO:tensorflow:loss = 0.404513, step = 4601 (0.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.588\n",
      "INFO:tensorflow:loss = 0.374918, step = 4701 (0.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.538\n",
      "INFO:tensorflow:loss = 0.325809, step = 4801 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.567\n",
      "INFO:tensorflow:loss = 0.281437, step = 4901 (0.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.701\n",
      "INFO:tensorflow:loss = 0.306849, step = 5001 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.751\n",
      "INFO:tensorflow:loss = 0.345483, step = 5101 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.616\n",
      "INFO:tensorflow:loss = 0.35221, step = 5201 (0.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.801\n",
      "INFO:tensorflow:loss = 0.364564, step = 5301 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.156\n",
      "INFO:tensorflow:loss = 0.507392, step = 5401 (0.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.801\n",
      "INFO:tensorflow:loss = 0.349892, step = 5501 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.356\n",
      "INFO:tensorflow:loss = 0.379291, step = 5601 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.524\n",
      "INFO:tensorflow:loss = 0.346776, step = 5701 (0.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.409\n",
      "INFO:tensorflow:loss = 0.462961, step = 5801 (0.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.7\n",
      "INFO:tensorflow:loss = 0.291862, step = 5901 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.258\n",
      "INFO:tensorflow:loss = 0.399172, step = 6001 (0.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.613\n",
      "INFO:tensorflow:loss = 0.341946, step = 6101 (0.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.182\n",
      "INFO:tensorflow:loss = 0.328986, step = 6201 (0.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.627\n",
      "INFO:tensorflow:loss = 0.371105, step = 6301 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.153\n",
      "INFO:tensorflow:loss = 0.357912, step = 6401 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.803\n",
      "INFO:tensorflow:loss = 0.304766, step = 6501 (0.504 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 204.52\n",
      "INFO:tensorflow:loss = 0.2782, step = 6601 (0.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.093\n",
      "INFO:tensorflow:loss = 0.338286, step = 6701 (0.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.983\n",
      "INFO:tensorflow:loss = 0.276604, step = 6801 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.305\n",
      "INFO:tensorflow:loss = 0.288703, step = 6901 (0.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.809\n",
      "INFO:tensorflow:loss = 0.481335, step = 7001 (0.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.227\n",
      "INFO:tensorflow:loss = 0.460785, step = 7101 (0.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.276\n",
      "INFO:tensorflow:loss = 0.324349, step = 7201 (0.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.698\n",
      "INFO:tensorflow:loss = 0.221085, step = 7301 (0.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.105\n",
      "INFO:tensorflow:loss = 0.369403, step = 7401 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.776\n",
      "INFO:tensorflow:loss = 0.262691, step = 7501 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.888\n",
      "INFO:tensorflow:loss = 0.354269, step = 7601 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.036\n",
      "INFO:tensorflow:loss = 0.332688, step = 7701 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.001\n",
      "INFO:tensorflow:loss = 0.316996, step = 7801 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.728\n",
      "INFO:tensorflow:loss = 0.409981, step = 7901 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.159\n",
      "INFO:tensorflow:loss = 0.395285, step = 8001 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.108\n",
      "INFO:tensorflow:loss = 0.409065, step = 8101 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.758\n",
      "INFO:tensorflow:loss = 0.309986, step = 8201 (0.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.456\n",
      "INFO:tensorflow:loss = 0.36392, step = 8301 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.261\n",
      "INFO:tensorflow:loss = 0.347837, step = 8401 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.189\n",
      "INFO:tensorflow:loss = 0.414186, step = 8501 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.665\n",
      "INFO:tensorflow:loss = 0.339273, step = 8601 (0.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.197\n",
      "INFO:tensorflow:loss = 0.271268, step = 8701 (0.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.258\n",
      "INFO:tensorflow:loss = 0.312436, step = 8801 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.612\n",
      "INFO:tensorflow:loss = 0.25211, step = 8901 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.809\n",
      "INFO:tensorflow:loss = 0.340979, step = 9001 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.148\n",
      "INFO:tensorflow:loss = 0.348646, step = 9101 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.054\n",
      "INFO:tensorflow:loss = 0.378816, step = 9201 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.723\n",
      "INFO:tensorflow:loss = 0.384061, step = 9301 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.058\n",
      "INFO:tensorflow:loss = 0.420725, step = 9401 (0.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.629\n",
      "INFO:tensorflow:loss = 0.317457, step = 9501 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.125\n",
      "INFO:tensorflow:loss = 0.417595, step = 9601 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.076\n",
      "INFO:tensorflow:loss = 0.354066, step = 9701 (0.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.051\n",
      "INFO:tensorflow:loss = 0.287353, step = 9801 (0.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.557\n",
      "INFO:tensorflow:loss = 0.366556, step = 9901 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.466\n",
      "INFO:tensorflow:loss = 0.305494, step = 10001 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.343\n",
      "INFO:tensorflow:loss = 0.348318, step = 10101 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.919\n",
      "INFO:tensorflow:loss = 0.372622, step = 10201 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.765\n",
      "INFO:tensorflow:loss = 0.266307, step = 10301 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.603\n",
      "INFO:tensorflow:loss = 0.348109, step = 10401 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.057\n",
      "INFO:tensorflow:loss = 0.530116, step = 10501 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.125\n",
      "INFO:tensorflow:loss = 0.407626, step = 10601 (0.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.061\n",
      "INFO:tensorflow:loss = 0.319306, step = 10701 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.037\n",
      "INFO:tensorflow:loss = 0.291126, step = 10801 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.125\n",
      "INFO:tensorflow:loss = 0.33501, step = 10901 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.528\n",
      "INFO:tensorflow:loss = 0.306994, step = 11001 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.413\n",
      "INFO:tensorflow:loss = 0.353218, step = 11101 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.004\n",
      "INFO:tensorflow:loss = 0.352588, step = 11201 (0.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.124\n",
      "INFO:tensorflow:loss = 0.422094, step = 11301 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.542\n",
      "INFO:tensorflow:loss = 0.217375, step = 11401 (0.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.88\n",
      "INFO:tensorflow:loss = 0.38889, step = 11501 (0.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.216\n",
      "INFO:tensorflow:loss = 0.366403, step = 11601 (0.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.584\n",
      "INFO:tensorflow:loss = 0.351003, step = 11701 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.746\n",
      "INFO:tensorflow:loss = 0.452124, step = 11801 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.435\n",
      "INFO:tensorflow:loss = 0.437939, step = 11901 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.392\n",
      "INFO:tensorflow:loss = 0.297685, step = 12001 (0.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.751\n",
      "INFO:tensorflow:loss = 0.408383, step = 12101 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.906\n",
      "INFO:tensorflow:loss = 0.304284, step = 12201 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.587\n",
      "INFO:tensorflow:loss = 0.253718, step = 12301 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.241\n",
      "INFO:tensorflow:loss = 0.254567, step = 12401 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.433\n",
      "INFO:tensorflow:loss = 0.39535, step = 12501 (0.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.824\n",
      "INFO:tensorflow:loss = 0.363775, step = 12601 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.206\n",
      "INFO:tensorflow:loss = 0.3374, step = 12701 (0.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.392\n",
      "INFO:tensorflow:loss = 0.380659, step = 12801 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.849\n",
      "INFO:tensorflow:loss = 0.32889, step = 12901 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.697\n",
      "INFO:tensorflow:loss = 0.359333, step = 13001 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.878\n",
      "INFO:tensorflow:loss = 0.352186, step = 13101 (0.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.368\n",
      "INFO:tensorflow:loss = 0.279858, step = 13201 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.988\n",
      "INFO:tensorflow:loss = 0.380663, step = 13301 (0.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.88\n",
      "INFO:tensorflow:loss = 0.382859, step = 13401 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.877\n",
      "INFO:tensorflow:loss = 0.472759, step = 13501 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.02\n",
      "INFO:tensorflow:loss = 0.36269, step = 13601 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.385\n",
      "INFO:tensorflow:loss = 0.268966, step = 13701 (0.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.241\n",
      "INFO:tensorflow:loss = 0.415408, step = 13801 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.262\n",
      "INFO:tensorflow:loss = 0.428197, step = 13901 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.656\n",
      "INFO:tensorflow:loss = 0.3867, step = 14001 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.986\n",
      "INFO:tensorflow:loss = 0.277092, step = 14101 (0.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.287\n",
      "INFO:tensorflow:loss = 0.366966, step = 14201 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.784\n",
      "INFO:tensorflow:loss = 0.357502, step = 14301 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.672\n",
      "INFO:tensorflow:loss = 0.260411, step = 14401 (0.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.756\n",
      "INFO:tensorflow:loss = 0.299273, step = 14501 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.597\n",
      "INFO:tensorflow:loss = 0.313859, step = 14601 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.098\n",
      "INFO:tensorflow:loss = 0.26709, step = 14701 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.437\n",
      "INFO:tensorflow:loss = 0.313459, step = 14801 (0.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.374142, step = 14901 (0.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.041\n",
      "INFO:tensorflow:loss = 0.461166, step = 15001 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.572\n",
      "INFO:tensorflow:loss = 0.50199, step = 15101 (0.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.476\n",
      "INFO:tensorflow:loss = 0.304045, step = 15201 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.401\n",
      "INFO:tensorflow:loss = 0.318741, step = 15301 (0.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.863\n",
      "INFO:tensorflow:loss = 0.329337, step = 15401 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.014\n",
      "INFO:tensorflow:loss = 0.339571, step = 15501 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.063\n",
      "INFO:tensorflow:loss = 0.363548, step = 15601 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.206\n",
      "INFO:tensorflow:loss = 0.337681, step = 15701 (0.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.786\n",
      "INFO:tensorflow:loss = 0.330242, step = 15801 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.932\n",
      "INFO:tensorflow:loss = 0.370908, step = 15901 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.965\n",
      "INFO:tensorflow:loss = 0.362477, step = 16001 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.502\n",
      "INFO:tensorflow:loss = 0.32253, step = 16101 (0.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.712\n",
      "INFO:tensorflow:loss = 0.314644, step = 16201 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.05\n",
      "INFO:tensorflow:loss = 0.377392, step = 16301 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.699\n",
      "INFO:tensorflow:loss = 0.385944, step = 16401 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.737\n",
      "INFO:tensorflow:loss = 0.256793, step = 16501 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.605\n",
      "INFO:tensorflow:loss = 0.287504, step = 16601 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.938\n",
      "INFO:tensorflow:loss = 0.312659, step = 16701 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.42\n",
      "INFO:tensorflow:loss = 0.46239, step = 16801 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.737\n",
      "INFO:tensorflow:loss = 0.258965, step = 16901 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.955\n",
      "INFO:tensorflow:loss = 0.386437, step = 17001 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.744\n",
      "INFO:tensorflow:loss = 0.34637, step = 17101 (0.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.656\n",
      "INFO:tensorflow:loss = 0.34972, step = 17201 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.17\n",
      "INFO:tensorflow:loss = 0.238941, step = 17301 (0.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.838\n",
      "INFO:tensorflow:loss = 0.415274, step = 17401 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.025\n",
      "INFO:tensorflow:loss = 0.395431, step = 17501 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.987\n",
      "INFO:tensorflow:loss = 0.297236, step = 17601 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.677\n",
      "INFO:tensorflow:loss = 0.390261, step = 17701 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.292\n",
      "INFO:tensorflow:loss = 0.267313, step = 17801 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.077\n",
      "INFO:tensorflow:loss = 0.344792, step = 17901 (0.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.204\n",
      "INFO:tensorflow:loss = 0.239833, step = 18001 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.92\n",
      "INFO:tensorflow:loss = 0.421076, step = 18101 (0.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.431\n",
      "INFO:tensorflow:loss = 0.456185, step = 18201 (0.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.858\n",
      "INFO:tensorflow:loss = 0.300569, step = 18301 (0.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.176\n",
      "INFO:tensorflow:loss = 0.424405, step = 18401 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.273\n",
      "INFO:tensorflow:loss = 0.194092, step = 18501 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.297\n",
      "INFO:tensorflow:loss = 0.424446, step = 18601 (0.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.674\n",
      "INFO:tensorflow:loss = 0.303847, step = 18701 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.349\n",
      "INFO:tensorflow:loss = 0.291338, step = 18801 (0.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.031\n",
      "INFO:tensorflow:loss = 0.449388, step = 18901 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.476\n",
      "INFO:tensorflow:loss = 0.387421, step = 19001 (0.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.492\n",
      "INFO:tensorflow:loss = 0.43187, step = 19101 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.047\n",
      "INFO:tensorflow:loss = 0.271959, step = 19201 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.231\n",
      "INFO:tensorflow:loss = 0.326155, step = 19301 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.215\n",
      "INFO:tensorflow:loss = 0.382327, step = 19401 (0.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.964\n",
      "INFO:tensorflow:loss = 0.345732, step = 19501 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.036\n",
      "INFO:tensorflow:loss = 0.374675, step = 19601 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.262\n",
      "INFO:tensorflow:loss = 0.238862, step = 19701 (0.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.684\n",
      "INFO:tensorflow:loss = 0.321282, step = 19801 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.838\n",
      "INFO:tensorflow:loss = 0.333655, step = 19901 (0.465 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into C:\\Users\\INVENTAR\\AppData\\Local\\Temp\\tmp5tlx89ug\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.35866.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SKCompat()"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = tf.contrib.learn.infer_real_valued_columns_from_input(x_norm)\n",
    "dnn_clf = tf.contrib.learn.DNNClassifier(hidden_units = [300,100], n_classes = 2,\n",
    "                                  feature_columns = feature_cols)\n",
    "dnn_clf = tf.contrib.learn.SKCompat(dnn_clf)\n",
    "dnn_clf.fit(x_norm, target,batch_size = 100, steps = 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\INVENTAR\\AppData\\Local\\Temp\\tmp5tlx89ug\\model.ckpt-20000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85081219943921427"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = dnn_clf.predict(x_test)\n",
    "accuracy_score(y_test, y_pred['classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95757, 4)"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_architecture = [\n",
    "    {\"input_dim\": 4, \"output_dim\": 8, \"activation\": \"relu\"},\n",
    "    {\"input_dim\": 8, \"output_dim\": 12, \"activation\": \"relu\"},\n",
    "    {\"input_dim\": 12, \"output_dim\": 8, \"activation\": \"relu\"},\n",
    "    {\"input_dim\": 8, \"output_dim\": 4, \"activation\": \"relu\"},\n",
    "    {\"input_dim\": 4, \"output_dim\": 1, \"activation\": \"sigmoid\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_layers(nn_architecture, seed = 99):\n",
    "    np.random.seed(seed)\n",
    "    number_of_layers = len(nn_architecture)\n",
    "    params_values = {}\n",
    "    \n",
    "    for ids, layer in enumerate(nn_architecture):\n",
    "        layer_idx = ids + 1\n",
    "        layer_input_size = layer['input_dim']\n",
    "        layer_output_size = layer['output_dim']\n",
    "        \n",
    "        \n",
    "        params_values['W' + str(layer_idx)] = np.random.randn(layer_output_size, layer_input_size) * 0.1\n",
    "        params_values['b' + str(layer_idx)] = np.random.randn(layer_output_size, 1) * 0.1\n",
    "        \n",
    "    return params_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras implementation of Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "\n",
    "import keras, tensorflow\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim = 4, activation = 'relu'))\n",
    "model.add(Dense(4, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.6985 - acc: 0.4310\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6792 - acc: 0.5594\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6650 - acc: 0.6404\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6528 - acc: 0.7247\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6412 - acc: 0.7976\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6304 - acc: 0.8270\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6197 - acc: 0.8408\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6084 - acc: 0.8439\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5967 - acc: 0.8447\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5851 - acc: 0.8448\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5735 - acc: 0.8449\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5621 - acc: 0.8449\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5508 - acc: 0.8449\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5397 - acc: 0.8449\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5286 - acc: 0.8450\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5176 - acc: 0.8449\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5068 - acc: 0.8448\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4960 - acc: 0.8449\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4853 - acc: 0.8450\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4747 - acc: 0.8449\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4641 - acc: 0.8449\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4538 - acc: 0.8450\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4436 - acc: 0.8450\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4337 - acc: 0.8450\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4243 - acc: 0.8451\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4154 - acc: 0.8448\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4073 - acc: 0.8447\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3998 - acc: 0.8446\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3931 - acc: 0.8442\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3872 - acc: 0.8437\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3820 - acc: 0.8436\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3774 - acc: 0.8434\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3736 - acc: 0.8432\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3703 - acc: 0.8431\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3675 - acc: 0.8430\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3652 - acc: 0.8429\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3633 - acc: 0.8428\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3617 - acc: 0.8429\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3603 - acc: 0.8428\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3592 - acc: 0.8427\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3583 - acc: 0.8428\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3575 - acc: 0.8428\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3569 - acc: 0.8428\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3564 - acc: 0.8429\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3560 - acc: 0.8428\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3556 - acc: 0.8428\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3552 - acc: 0.8429\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3549 - acc: 0.8430\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3546 - acc: 0.8431\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3544 - acc: 0.8432\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3541 - acc: 0.8431\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3539 - acc: 0.8432\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3537 - acc: 0.8434\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3535 - acc: 0.8435\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3533 - acc: 0.8436\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3531 - acc: 0.8435\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3530 - acc: 0.8435\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3528 - acc: 0.8436\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3527 - acc: 0.8436\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3526 - acc: 0.8438\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3524 - acc: 0.8441\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3523 - acc: 0.8442\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3522 - acc: 0.8442\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3521 - acc: 0.8442\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3520 - acc: 0.8443\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3519 - acc: 0.8443\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3518 - acc: 0.8443\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3517 - acc: 0.8442\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3516 - acc: 0.8443\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3515 - acc: 0.8443\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3514 - acc: 0.8443\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3513 - acc: 0.8443\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3512 - acc: 0.8443\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3511 - acc: 0.8443\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3510 - acc: 0.8443\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3510 - acc: 0.8443\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3509 - acc: 0.8442\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3508 - acc: 0.8442\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3507 - acc: 0.8442\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3506 - acc: 0.8442\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3505 - acc: 0.8442\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3504 - acc: 0.8442\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3503 - acc: 0.8443\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3503 - acc: 0.8445\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3502 - acc: 0.8446\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3501 - acc: 0.8447\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3500 - acc: 0.8447\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3499 - acc: 0.8448\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3499 - acc: 0.8448\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3498 - acc: 0.8448\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3497 - acc: 0.8449\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3496 - acc: 0.8449\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3496 - acc: 0.8449\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3495 - acc: 0.8449\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3494 - acc: 0.8449\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3493 - acc: 0.8449\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3493 - acc: 0.8449\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3492 - acc: 0.8449\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3492 - acc: 0.8449\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3491 - acc: 0.8450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dfa3c9e898>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile model\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs = 100, steps_per_epoch = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95757/95757 [==============================] - 2s 17us/step\n",
      "\n",
      "acc: 84.50%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(x_train, y_train)\n",
    "print('\\n%s: %.2f%%' % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84.497216913894974, 84.705274205423024)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "test_score = accuracy_score(prediction.round(), y_test)\n",
    "scores[1]*100, test_score*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(300, input_dim = 4, activation = 'relu')) # layer 1\n",
    "model.add(Dense(800, activation = 'relu')) # layer 2\n",
    "model.add(Dense(500, activation = 'relu')) # layer 3\n",
    "model.add(Dense(200, activation = 'relu')) # layer 5\n",
    "model.add(Dense(10, activation = 'relu')) # layer 6\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10/10 [==============================] - 140s 14s/step - loss: 0.6931 - acc: 0.5121\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 72s 7s/step - loss: 0.6796 - acc: 0.7619\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 72s 7s/step - loss: 0.6686 - acc: 0.7966\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 72s 7s/step - loss: 0.6582 - acc: 0.8153\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 72s 7s/step - loss: 0.6484 - acc: 0.8208\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 72s 7s/step - loss: 0.6389 - acc: 0.8234\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 72s 7s/step - loss: 0.6298 - acc: 0.8253\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 72s 7s/step - loss: 0.6209 - acc: 0.8272\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 72s 7s/step - loss: 0.6123 - acc: 0.8284\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 72s 7s/step - loss: 0.6038 - acc: 0.8288\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 72s 7s/step - loss: 0.5954 - acc: 0.8293\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 72s 7s/step - loss: 0.5871 - acc: 0.8297\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 72s 7s/step - loss: 0.5788 - acc: 0.8302\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 72s 7s/step - loss: 0.5705 - acc: 0.8306\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 72s 7s/step - loss: 0.5622 - acc: 0.8311\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 72s 7s/step - loss: 0.5540 - acc: 0.8317\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 72s 7s/step - loss: 0.5457 - acc: 0.8324\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 72s 7s/step - loss: 0.5374 - acc: 0.8331\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 72s 7s/step - loss: 0.5290 - acc: 0.8337\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 60s 6s/step - loss: 0.5207 - acc: 0.8342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e02f7f9f28>"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile model\n",
    "import tensorflow as tf\n",
    "learning_rate = 0.0001\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'sgd', metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs = 20, steps_per_epoch = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95757/95757 [==============================] - 17s 178us/step\n",
      "\n",
      "acc: 83.45%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(x_train, y_train)\n",
    "print('\\n%s: %.2f%%' % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83.446640976763277, 83.599367158006871)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "test_score = accuracy_score(prediction.round(), y_test)\n",
    "scores[1]*100, test_score*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(300, input_dim = 4, activation = 'relu')) \n",
    "model.add(Dense(1000, activation = 'relu')) \n",
    "model.add(Dense(400, activation = 'relu')) \n",
    "model.add(Dense(10, activation = 'relu')) \n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10/10 [==============================] - 62s 6s/step - loss: 0.6829 - acc: 0.7769\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 55s 5s/step - loss: 0.6698 - acc: 0.8331\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 55s 5s/step - loss: 0.6552 - acc: 0.8327\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 55s 6s/step - loss: 0.6383 - acc: 0.8313\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 55s 6s/step - loss: 0.6184 - acc: 0.8293\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 56s 6s/step - loss: 0.5964 - acc: 0.8273\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 56s 6s/step - loss: 0.5757 - acc: 0.8267\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 56s 6s/step - loss: 0.5569 - acc: 0.8267\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 57s 6s/step - loss: 0.5401 - acc: 0.8273\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 60s 6s/step - loss: 0.5249 - acc: 0.8281\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 59s 6s/step - loss: 0.5111 - acc: 0.8288\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 56s 6s/step - loss: 0.4985 - acc: 0.8298\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 56s 6s/step - loss: 0.4869 - acc: 0.8305\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 56s 6s/step - loss: 0.4762 - acc: 0.8313\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 57s 6s/step - loss: 0.4662 - acc: 0.8324\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 56s 6s/step - loss: 0.4570 - acc: 0.8333\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 56s 6s/step - loss: 0.4484 - acc: 0.8341\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 56s 6s/step - loss: 0.4404 - acc: 0.8350\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 56s 6s/step - loss: 0.4330 - acc: 0.8359\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 56s 6s/step - loss: 0.4262 - acc: 0.8367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e03a7db240>"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer = 'sgd', metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs = 20, steps_per_epoch = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(300, input_dim = 4, activation = 'relu')) \n",
    "model.add(Dense(800, activation = 'relu')) \n",
    "model.add(Dense(100, activation = 'relu')) \n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 45s 4s/step - loss: 0.5007 - acc: 0.7909\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 34s 3s/step - loss: 0.3558 - acc: 0.8427\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 35s 3s/step - loss: 0.3502 - acc: 0.8460\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 35s 3s/step - loss: 0.3476 - acc: 0.8463\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 35s 3s/step - loss: 0.3469 - acc: 0.8465\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 35s 4s/step - loss: 0.3465 - acc: 0.8465\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 35s 3s/step - loss: 0.3462 - acc: 0.8472\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 35s 4s/step - loss: 0.3460 - acc: 0.8472\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.3458 - acc: 0.8474\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 35s 4s/step - loss: 0.3457 - acc: 0.8479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e0638974a8>"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs = 10, steps_per_epoch = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim = 4, activation = 'relu')) \n",
    "model.add(Dense(800, activation = 'relu')) \n",
    "model.add(Dense(300, activation = 'relu')) \n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 71s 7s/step - loss: 0.4578 - acc: 0.7867\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 63s 6s/step - loss: 0.3575 - acc: 0.8437\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 63s 6s/step - loss: 0.3494 - acc: 0.8462\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 63s 6s/step - loss: 0.3478 - acc: 0.8466\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 63s 6s/step - loss: 0.3469 - acc: 0.8469\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 6209s 621s/step - loss: 0.3464 - acc: 0.8471\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 50s 5s/step - loss: 0.3461 - acc: 0.8473\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 50s 5s/step - loss: 0.3459 - acc: 0.8477\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 49s 5s/step - loss: 0.3457 - acc: 0.8478\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 49s 5s/step - loss: 0.3456 - acc: 0.8482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e0634dc8d0>"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs = 10, steps_per_epoch = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Neural nets\n",
    "n_input = 4\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 500\n",
    "n_hidden3 = 20\n",
    "n_output = 1\n",
    "\n",
    "\n",
    "#he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "#hidden1 = tf.layers.dense(x_train, n_hidden1, activation = tf.nn.relu,\n",
    "#                         kernel_initializer =he_init, name = 'hidden1')\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = (None, n_input), name = 'X')\n",
    "y = tf.placeholder(tf.int32, shape = (None), name = 'y')\n",
    "\n",
    "\n",
    "training = tf.placeholder_with_default(False, shape = (), name = 'training')\n",
    "with tf.var_scope('dnn', reuse = True):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, name = 'hidden1',\n",
    "                             activation = tf.nn.relu)\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, name = 'hidden2',\n",
    "                              activation = tf.nn.relu)\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, name = 'hidden3',\n",
    "                             activation = tf.nn.relu)\n",
    "    logits = tf.layers.dense(hidden3, n_outputs, name = 'outputs')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = tf.placeholder_with_default(False, shape = (), name = 'training')\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, name = 'hidden1')\n",
    "bn1 = tf.layers.batch_normalization(hidden1, training = training, momentum = 0.9)\n",
    "bn1_act = tf.nn.elu(bn1)\n",
    "hidden2 = tf.layers.dense(bn1_act, n_hidden2, name = 'hidden2')\n",
    "bn2 = tf.layers.batch_normalization(hidden2, training = training, momentum = 0.9)\n",
    "bn2_act = tf.nn.elu(bn2)\n",
    "logits_before_bn = tf.layers.dense(bn2_act, n_outputs, name = 'outputs')\n",
    "logits = tf.layers.batch_normalization(logits_before_bn, training = training,\n",
    "                                      momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "val_x_train, val_x_test, val_y_train, val_y_test = train_test_split(x_test, y_test, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('eval'):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_epochs = 40\n",
    "batch_size = 200\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    start, stop = 0,0\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(x_train.shape[0]//batch_size):\n",
    "            stop = start + batch_size\n",
    "            x_batch, y_batch = x_train[start:stop], y_train[start:stop]\n",
    "            sess.run(training_op, feed_dict = {X:x_batch, y:y_batch})\n",
    "            start = stop+ 1\n",
    "        acc_train = accuracy.eval(feed_dict = {X: x_batch, y: y_batch})\n",
    "        acc_val = accuracy.eval(feed_dict = {X: x_val, y: y_val})\n",
    "        print(epoch, 'Train accuracy: ', acc_train, 'val_accuracy: ', acc_val)\n",
    "    import os\n",
    "    cwd = os.getcwd() + '/my_model_final.ckpt'\n",
    "    save_path = saver.save(sess, cwd)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "n_epochs = 20 \n",
    "batch_size = 300\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    start, stop = 0,0\n",
    "    for epoch in range(n_epochs):\n",
    "        train = []\n",
    "        for iteration in range(x_train.shape[1]//batch_size):\n",
    "            stop = start + batch_size\n",
    "            x_batch, y_batch = x_train[start:stop], y_train[start:stop]\n",
    "            sess.run([training_op, extra_update_ops],\n",
    "                     feed_dict = {training:True, X: x_batch, y: y_batch})\n",
    "            start = stop\n",
    "            acc_train = accuracy.eval(feed_dict = {X: x_batch, y: y_batch})\n",
    "            print(acc_train)\n",
    "            train.append(acc_train)\n",
    "        #accuracy_val = accuracy.eval(feed_dict = {X:val_x_train, y:val_y_train})\n",
    "        #acc_train = accuracy.eval(feed_dict = {X: x_batch, y: y_batch})\n",
    "        #acc_val = accuracy.eval(feed_dict = {X: x_val, y: y_val})\n",
    "        #print(epoch, 'Train accuracy: ', acc_train, 'val_accuracy: ', acc_val)\n",
    "        #print(epoch, \"Train accuracy: \", sum(train)/len(train))\n",
    "    save_path = saver.save(sess, './my_model_final_k.ckpt')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training DNN using pure Tensorflow\n",
    "\n",
    "n_inputs =4\n",
    "n_hidden1 = 20\n",
    "n_hidden2 = 15\n",
    "n_outputs = 1\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = (200, n_inputs), name = 'X')\n",
    "y = tf.placeholder(tf.int64, shape = (200), name = 'y')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def neuron_layer(x, n_neurons, name, activation = None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(x.shape[1])\n",
    "        stddev = 2/np.sqrt(n_inputs + n_neurons)\n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev = stddev)\n",
    "        w =tf.Variable(init, name = 'kernel')\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name = 'bias')\n",
    "        z = tf.matmul(x, w) + b\n",
    "        if activation is not None:\n",
    "            return activation(z)\n",
    "        else:\n",
    "            return z\n",
    "        \n",
    "with tf.name_scope('dnn'):\n",
    "    hidden1 = neuron_layer(x, n_hidden1, name = 'hidden1', \n",
    "                          activation = tf.nn.relu)\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, name = 'hidden2', \n",
    "                           activation = tf.nn.relu)\n",
    "    logits = neuron_layer(hidden2, n_outputs, name = 'outputs')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with tf.name_scope('dnn'):\n",
    "    hidden1 = tf.layers.dense(x, n_hidden1, name = 'hidden1',\n",
    "                             activation = tf.nn.relu)\n",
    "    hidden2 = tf.layers.dense(hidden1, hidden2, name = hidden2, \n",
    "                             activation = tf.nn.relu)\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name = 'outputs')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y,\n",
    "                                                             logits = logits)\n",
    "    loss = tf.reduce_mean(xentropy, name = 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('eval'):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "inint = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_val, test_x, y_val, test_y = train_test_split(x_test, y_test, test_size = 0.4, random_state = 42)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "summary_op = tf.summary.merge_all()\n",
    "\n",
    "    sess = tf.InteractiveSession()\n",
    "    writer = tf.summary.FileWriter(\"./data\", sess.graph)\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    # Train\n",
    "    for i in range(epochs):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "         _, summary = sess.run([train_step,summary_op], feed_dict={input_data: batch_xs, y_: batch_ys})\n",
    "     writer.add_summary(summary)\n",
    "\n",
    "     if i % 10 ==0:\n",
    "          test_xs, test_ys = mnist.train.next_batch(batch_size)\n",
    "          test_accuracy = sess.run(accuracy, feed_dict = {input_data : test_xs, y_ : test_ys})\n",
    "    writer.close()\n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "n_epochs = 40\n",
    "batch_size = 200\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    start, stop = 0,0\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(x_train.shape[0]//batch_size):\n",
    "            stop = start + batch_size\n",
    "            x_batch, y_batch = x_train[start:stop], y_train[start:stop]\n",
    "            sess.run(training_op, feed_dict = {X:x_batch, y:y_batch})\n",
    "            start = stop+ 1\n",
    "        acc_train = accuracy.eval(feed_dict = {X: x_batch, y: y_batch})\n",
    "        acc_val = accuracy.eval(feed_dict = {X: x_val, y: y_val})\n",
    "        print(epoch, 'Train accuracy: ', acc_train, 'val_accuracy: ', acc_val)\n",
    "    import os\n",
    "    cwd = os.getcwd() + '/my_model_final.ckpt'\n",
    "    save_path = saver.save(sess, cwd)\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with tf.Session() as sess:\n",
    "    cwd = os.getcwd() + '/my_model_final.ckpt'\n",
    "    saver.restore(sess, cwd)\n",
    "    z = logits.eval(feed_dict = {X:test_x})\n",
    "    y_pred = np.argmax(z, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95757, 4)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPECIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The keras module is not an IPython extension.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "%load_ext keras\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "\n",
    "\n",
    "import keras.Flatten as flatten\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "#x_val, test_x, y_val, test_y\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train)\n",
    "model = models.Sequential()\n",
    "# input layer\n",
    "model.add(layers.Dense(20, activation = 'relu', input_shape = (4,)))\n",
    "# hidden layers\n",
    "model.add(layers.Dropout(0.3, noise_shape = None, seed = None))\n",
    "model.add(layers.Dense(20, activation = 'relu'))\n",
    "model.add(layers.Dropout(0.2, noise_shape = None, seed = None))\n",
    "model.add(layers.Dense(30, activation = tf.nn.softmax))\n",
    "\n",
    "# output layer \n",
    "model.add(flatten())\n",
    "model.add(layers.Dense(1, activation = tf.nn.softmax))\n",
    "model.compile(optimizer = 'sgd', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "history = model.fit(x_train, y_train, epochs = 20, batch_size = 8000, validation_data = (x_val, test_x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.84502438464 0.847209386112\n",
      "4 0.843739883246 0.846050220085\n",
      "5 0.848094656265 0.849825341876\n",
      "6 0.847582944328 0.849559046978\n",
      "7 0.84761427363 0.849042121587\n",
      "8 0.847645602932 0.848854148718\n",
      "9 0.847113004793 0.849433731731\n",
      "10 0.847676932235 0.849183101239\n",
      "11 0.847927566653 0.84910477921\n",
      "12 0.848627254404 0.853381161986\n",
      "13 0.848481050994 0.853443819609\n",
      "14 0.848366176885 0.852989551841\n"
     ]
    }
   ],
   "source": [
    "def best_feature_number(x, y, n_default):\n",
    "    for i in range(3,n_default):\n",
    "        test = SelectKBest(score_func =chi2, k = i)\n",
    "        fit = test.fit(x,y)\n",
    "        # summarize scores\n",
    "        np.set_printoptions(precision = 3)\n",
    "        features = fit.transform(x)\n",
    "        \n",
    "        from sklearn.preprocessing import MinMaxScaler\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        from sklearn.preprocessing import Normalizer\n",
    "        min_max = MinMaxScaler()\n",
    "        std = StandardScaler()\n",
    "        norm = Normalizer()\n",
    "\n",
    "        x_new = min_max.fit_transform(features)\n",
    "        x_std = std.fit_transform(x_new)\n",
    "        x_norm = std.fit_transform(x_std)\n",
    "        \n",
    "        from sklearn.model_selection import train_test_split\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x_norm, y, test_size = 0.4, random_state = 42)\n",
    "\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        log = LogisticRegression()\n",
    "        \n",
    "        log.fit(x_train, y_train)\n",
    "        value = log.score(x_train, y_train)\n",
    "\n",
    "        prediction = log.predict(x_test)\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        solution = accuracy_score(prediction, y_test)\n",
    "        print(i, value,solution)\n",
    "        \n",
    "    return \n",
    "best_feature_number(x, target, n_default = 15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# recursive feature elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 3\n",
      "Selected Features: [False False False False False False False False False  True  True  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False]\n",
      "Feature Ranking: [51  4 50 39 53 45 48 38  3  1  1  1  2 19 28 29 24 59 16 18 57 20 23 31 60\n",
      " 26 43 37 36 54 56 30 22 62  5 41 49 27 64 34 17 33 63 40 46 42 25 32 58 44\n",
      " 61 55 65 47 35 21 52 14 13 12 15 11  6 10  9  8  7]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "# feature extraction\n",
    "model = LogisticRegression()\n",
    "rfe = RFE(model, 3)\n",
    "fit = rfe.fit(x, target)\n",
    "print('Num Features: %d' % fit.n_features_)\n",
    "print('Selected Features: %s' % fit.support_)\n",
    "print('Feature Ranking: %s' % fit.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paymentRatio\n",
      "FirstPaymentDefault\n",
      "clientGender_FEMALE\n"
     ]
    }
   ],
   "source": [
    "for i, j in zip(fit.support_, x.columns):\n",
    "    if i == True:\n",
    "        print(j)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_feature = x[['paymentRatio', 'FirstPaymentDefault','clientGender_FEMALE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84589839344344475"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(new_feature, target)\n",
    "model.score(new_feature, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.fit(new_feature, target)\n",
    "train = forest.score(new_feature, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.845898393443 0.847209386112\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(new_feature, target, test_size = 0.4, random_state = 42)\n",
    "\n",
    "\n",
    "prediction = forest.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "solution = accuracy_score(prediction, y_test)\n",
    "print(train, solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84502438464 0.847209386112\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(new_feature, target, test_size = 0.4, random_state = 42)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log = LogisticRegression()\n",
    "        \n",
    "log.fit(x_train, y_train)\n",
    "value = log.score(x_train, y_train)\n",
    "\n",
    "prediction = log.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "solution = accuracy_score(prediction, y_test)\n",
    "print(value, solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance sum: 0.999999998299\n",
      "[[  9.961e-01   4.229e-07   1.301e-05   4.636e-08   8.852e-02  -6.524e-06\n",
      "    3.634e-05   1.618e-07  -1.899e-07  -4.987e-08  -2.082e-07  -3.738e-07\n",
      "    3.738e-07  -2.603e-09   1.280e-07  -7.223e-09  -1.208e-08  -7.107e-09\n",
      "   -1.228e-09  -5.389e-09  -2.191e-08   1.123e-09  -8.402e-09  -4.913e-09\n",
      "   -5.113e-09  -1.553e-08  -1.431e-08   4.734e-09  -3.718e-09  -3.037e-09\n",
      "   -8.295e-10  -1.794e-08   3.070e-09  -1.558e-09  -3.494e-09  -1.182e-08\n",
      "   -2.956e-08   1.947e-07  -3.320e-11  -1.867e-08  -8.286e-09  -1.107e-07\n",
      "   -2.167e-11  -3.031e-08  -1.334e-08  -3.127e-08  -1.535e-08   8.510e-08\n",
      "   -4.632e-09  -4.561e-09  -1.697e-10  -1.588e-09   2.642e-11   7.972e-07\n",
      "    1.020e-08  -8.105e-07   3.080e-09   1.865e-07  -1.003e-07  -3.599e-08\n",
      "   -4.188e-08  -8.276e-09  -6.216e-08  -3.255e-07   5.195e-07  -1.250e-07\n",
      "   -6.850e-09]\n",
      " [ -8.852e-02   5.363e-06   2.593e-05   2.227e-05   9.961e-01  -1.021e-04\n",
      "    1.010e-03   3.759e-07   2.772e-07  -5.188e-07  -1.000e-06   9.191e-08\n",
      "   -9.191e-08  -3.468e-08   3.335e-07   1.522e-09  -1.998e-08  -1.783e-08\n",
      "    4.891e-09   9.442e-09  -4.946e-08  -9.471e-09   3.616e-09  -7.356e-08\n",
      "   -5.114e-09  -2.479e-08  -5.470e-08  -1.670e-08  -1.967e-09  -3.088e-08\n",
      "   -2.973e-09   2.739e-08   9.666e-09  -3.552e-09   1.367e-08  -5.190e-08\n",
      "   -5.974e-08   5.563e-07   5.538e-10  -4.021e-09  -3.691e-08  -1.392e-07\n",
      "    6.023e-10  -6.915e-08  -1.108e-07  -1.986e-07   3.083e-08   1.972e-08\n",
      "    4.484e-09  -5.812e-09   5.074e-09   4.387e-10  -2.453e-10   1.410e-06\n",
      "    4.390e-08  -1.483e-06   2.975e-08   1.872e-07   2.091e-07   1.987e-07\n",
      "   -3.245e-07  -2.704e-07   4.236e-08  -3.286e-07  -1.178e-07   4.201e-07\n",
      "   -1.604e-08]\n",
      " [ -5.327e-05  -1.964e-03   2.717e-03  -1.052e-02   1.014e-03   6.806e-02\n",
      "   -9.976e-01   3.165e-03  -1.035e-03   3.293e-04   4.602e-04   3.636e-05\n",
      "   -3.636e-05  -7.901e-06   2.710e-05  -1.362e-06  -1.091e-05  -4.301e-06\n",
      "    4.538e-06   1.775e-05   9.706e-07  -6.671e-07   1.187e-05  -2.461e-05\n",
      "   -3.171e-06  -2.011e-05   1.897e-05  -8.887e-07   4.082e-07   1.740e-05\n",
      "    2.301e-06  -1.356e-05  -5.930e-06   4.909e-06   6.059e-06   1.558e-05\n",
      "   -3.526e-06  -1.177e-04  -2.550e-07   8.153e-06   2.995e-05   2.326e-05\n",
      "   -2.090e-07  -3.791e-07   1.742e-05   5.055e-06   3.332e-06  -1.573e-05\n",
      "    3.619e-06   6.256e-06   1.222e-06   5.067e-06   1.540e-07   1.554e-04\n",
      "    1.244e-05  -1.908e-04   2.282e-05  -3.382e-04   1.041e-04   2.564e-05\n",
      "    7.293e-06   2.012e-04   1.501e-06  -1.637e-04   4.299e-05   9.814e-05\n",
      "    2.102e-05]\n",
      " [ -1.064e-05   2.661e-03   9.962e-01  -2.605e-02  -3.156e-05  -6.265e-02\n",
      "   -1.272e-03   1.691e-03  -1.121e-04  -1.540e-03  -3.286e-03  -4.560e-03\n",
      "    4.560e-03  -1.290e-04   1.113e-04  -2.810e-05   1.163e-05  -3.858e-04\n",
      "   -3.649e-05  -3.338e-05  -4.265e-05  -6.410e-05  -2.255e-04  -5.268e-05\n",
      "   -8.875e-05  -3.836e-04  -5.633e-05  -4.116e-04  -3.040e-05  -2.595e-04\n",
      "   -1.275e-05   1.687e-04  -8.968e-05  -1.903e-05  -5.664e-05   8.016e-05\n",
      "   -2.169e-04   1.569e-04   2.055e-06   1.413e-04   6.811e-05   1.406e-03\n",
      "    1.022e-06   2.158e-05  -2.224e-04   7.354e-04  -9.976e-05   6.124e-05\n",
      "   -1.431e-05   1.398e-05  -2.202e-05   1.786e-06   4.243e-06   3.626e-02\n",
      "    1.220e-03  -3.840e-02   9.230e-04  -1.952e-03   2.930e-03   1.672e-03\n",
      "   -1.466e-03  -1.184e-03  -6.866e-04  -9.909e-03   8.825e-03   1.861e-03\n",
      "   -9.011e-05]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# feature extraction\n",
    "pca = PCA(n_components = 4)\n",
    "fit = pca.fit(x)\n",
    "# summarize components\n",
    "print('Explained Variance sum: %s' % fit.explained_variance_ratio_.sum())\n",
    "print(fit.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 67)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.components_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.394  0.605  0.001]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(new_feature, target)\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.109  0.06   0.372  0.459]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(x_norm, target)\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84605022008490105"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(prediction, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41913  4045]\n",
      " [ 5783 12098]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_test, prediction)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71114507406536553"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.91      0.90     45958\n",
      "          1       0.75      0.68      0.71     17881\n",
      "\n",
      "avg / total       0.84      0.85      0.84     63839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
